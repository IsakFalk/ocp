{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35a4c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch, Data\n",
    "import functorch\n",
    "import copy\n",
    "from ocpmodels.transfer_learning.models.distribution_regression import (\n",
    "    GaussianKernel,\n",
    "    KernelMeanEmbeddingRidgeRegression,\n",
    "    LinearMeanEmbeddingKernel,\n",
    "    StandardizedOutputRegression,\n",
    "    median_heuristic,\n",
    ")\n",
    "\n",
    "from ocpmodels.transfer_learning.common.utils import (\n",
    "    ATOMS_TO_GRAPH_KWARGS,\n",
    "    load_xyz_to_pyg_batch,\n",
    "    load_xyz_to_pyg_data,\n",
    ")\n",
    "from ocpmodels.transfer_learning.loaders import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43058f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isak/life/references/projects/src/python_lang/ocp\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3a4bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error(s) in loading state_dict for SchNetWrap:\n",
      "\tUnexpected key(s) in state_dict: \"atomic_mass\", \"interactions.2.mlp.0.weight\", \"interactions.2.mlp.0.bias\", \"interactions.2.mlp.2.weight\", \"interactions.2.mlp.2.bias\", \"interactions.2.conv.lin1.weight\", \"interactions.2.conv.lin2.weight\", \"interactions.2.conv.lin2.bias\", \"interactions.2.conv.nn.0.weight\", \"interactions.2.conv.nn.0.bias\", \"interactions.2.conv.nn.2.weight\", \"interactions.2.conv.nn.2.bias\", \"interactions.2.lin.weight\", \"interactions.2.lin.bias\", \"interactions.3.mlp.0.weight\", \"interactions.3.mlp.0.bias\", \"interactions.3.mlp.2.weight\", \"interactions.3.mlp.2.bias\", \"interactions.3.conv.lin1.weight\", \"interactions.3.conv.lin2.weight\", \"interactions.3.conv.lin2.bias\", \"interactions.3.conv.nn.0.weight\", \"interactions.3.conv.nn.0.bias\", \"interactions.3.conv.nn.2.weight\", \"interactions.3.conv.nn.2.bias\", \"interactions.3.lin.weight\", \"interactions.3.lin.bias\", \"interactions.4.mlp.0.weight\", \"interactions.4.mlp.0.bias\", \"interactions.4.mlp.2.weight\", \"interactions.4.mlp.2.bias\", \"interactions.4.conv.lin1.weight\", \"interactions.4.conv.lin2.weight\", \"interactions.4.conv.lin2.bias\", \"interactions.4.conv.nn.0.weight\", \"interactions.4.conv.nn.0.bias\", \"interactions.4.conv.nn.2.weight\", \"interactions.4.conv.nn.2.bias\", \"interactions.4.lin.weight\", \"interactions.4.lin.bias\". \n"
     ]
    }
   ],
   "source": [
    "#%cd ../..\n",
    "### Load checkpoint\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/s2ef_efwt/all/schnet/schnet_all_large.pt\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "\n",
    "### Load data\n",
    "DATA_PATH = Path(\"data/luigi/example-traj-Fe-N2-111.xyz\")\n",
    "raw_data, data_batch, num_frames, num_atoms = load_xyz_to_pyg_batch(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "raw_data, data_list, num_frames, num_atoms = load_xyz_to_pyg_data(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "representation_layer = 2\n",
    "base_loader = BaseLoader(\n",
    "    checkpoint[\"config\"],\n",
    "    representation=True,\n",
    "    representation_kwargs={\n",
    "        \"representation_layer\": representation_layer,\n",
    "    },\n",
    ")\n",
    "base_loader.load_checkpoint(CHECKPOINT_PATH, strict_load=False)\n",
    "model = base_loader.model\n",
    "model.to(device)\n",
    "model.mekrr_forces = True\n",
    "model.regress_forces = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365fb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.common.utils import get_pbc_distances, radius_graph_pbc\n",
    "#from torch_scatter import scatter, segment_coo, segment_csr\n",
    "# import torch_scatter\n",
    "\n",
    "# # For the CSR operator:\n",
    "# class SumCSR(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, values, groups):\n",
    "#         ctx.save_for_backward(groups)\n",
    "#         return torch_scatter.segment_csr(values, groups, reduce=\"sum\")\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         (groups,) = ctx.saved_tensors\n",
    "#         return GatherCSR.apply(grad_output, groups), None\n",
    "\n",
    "\n",
    "# class GatherCSR(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, values, groups):\n",
    "#         ctx.save_for_backward(groups)\n",
    "#         return torch_scatter.gather_csr(values, groups)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         (groups,) = ctx.saved_tensors\n",
    "#         return SumCSR.apply(grad_output, groups), None\n",
    "    \n",
    "# def segment_csr(values, groups, reduce=None):\n",
    "#     return SumCSR.apply(values, groups)\n",
    "\n",
    "\n",
    "# # For the COO operator:\n",
    "# class SumCOO(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, values, groups, dim_size):\n",
    "#         ctx.save_for_backward(groups)\n",
    "#         ctx.dim_size = dim_size\n",
    "#         return torch_scatter.segment_coo(\n",
    "#             values, groups, dim_size=dim_size, reduce=\"sum\"\n",
    "#         )\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         (groups,) = ctx.saved_tensors\n",
    "#         return GatherCOO.apply(grad_output, groups, ctx.dim_size), None, None\n",
    "\n",
    "\n",
    "# class GatherCOO(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, values, groups, dim_size):\n",
    "#         ctx.save_for_backward(groups)\n",
    "#         ctx.dim_size = dim_size\n",
    "#         return torch_scatter.gather_coo(values, groups)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         (groups,) = ctx.saved_tensors\n",
    "#         return SumCOO.apply(grad_output, groups, ctx.dim_size), None, None\n",
    "\n",
    "# def segment_coo(values, groups, dim_size, reduce=None):\n",
    "#     return SumCOO.apply(values, groups, dim_size)\n",
    "\n",
    "def my_radius_graph_pbc(data, radius, max_num_neighbors_threshold, pbc=[True, True, True]):\n",
    "    edge_index, unit_cell, _ = radius_graph_pbc_(data, radius, max_num_neighbors_threshold, pbc)\n",
    "    neighbors = []\n",
    "    try:\n",
    "        for dat in data.to_data_list():\n",
    "            _, _, n = radius_graph_pbc_(dat, radius, max_num_neighbors_threshold)\n",
    "            neighbors.append(n)\n",
    "    except Exception as err:\n",
    "        _, _, neighbors = radius_graph_pbx_(data, radius, max_num_neighbors_threshold)\n",
    "    neighbors = torch.stack(neighbors).long()\n",
    "    return edge_index, unit_cell, neighbors\n",
    "\n",
    "def radius_graph_pbc_(data, radius, max_num_neighbors_threshold, pbc=[True, True, True]):\n",
    "    device = data.pos.device\n",
    "    batch_size = len(data.natoms)\n",
    "\n",
    "    if hasattr(data, \"pbc\"):\n",
    "        data.pbc = torch.atleast_2d(data.pbc)\n",
    "        for i in range(3):\n",
    "            if not torch.any(data.pbc[:, i]).item():\n",
    "                pbc[i] = False\n",
    "            elif torch.all(data.pbc[:, i]).item():\n",
    "                pbc[i] = True\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    \"Different structures in the batch have different PBC configurations. This is not currently supported.\"\n",
    "                )\n",
    "\n",
    "    # position of the atoms\n",
    "    atom_pos = data.pos\n",
    "\n",
    "    # Before computing the pairwise distances between atoms, first create a list of atom indices to compare for the entire batch\n",
    "    num_atoms_per_image = data.natoms\n",
    "    num_atoms_per_image_sqr = (num_atoms_per_image**2).long()\n",
    "\n",
    "    # index offset between images\n",
    "    index_offset = torch.cumsum(num_atoms_per_image, dim=0) - num_atoms_per_image\n",
    "\n",
    "    index_offset_expand = torch.repeat_interleave(index_offset, num_atoms_per_image_sqr)\n",
    "    num_atoms_per_image_expand = torch.repeat_interleave(num_atoms_per_image, num_atoms_per_image_sqr)\n",
    "\n",
    "    # Compute a tensor containing sequences of numbers that range from 0 to num_atoms_per_image_sqr for each image\n",
    "    # that is used to compute indices for the pairs of atoms. This is a very convoluted way to implement\n",
    "    # the following (but 10x faster since it removes the for loop)\n",
    "    # for batch_idx in range(batch_size):\n",
    "    #    batch_count = torch.cat([batch_count, torch.arange(num_atoms_per_image_sqr[batch_idx], device=device)], dim=0)\n",
    "    num_atom_pairs = torch.sum(num_atoms_per_image_sqr)\n",
    "    index_sqr_offset = torch.cumsum(num_atoms_per_image_sqr, dim=0) - num_atoms_per_image_sqr\n",
    "    index_sqr_offset = torch.repeat_interleave(index_sqr_offset, num_atoms_per_image_sqr)\n",
    "    atom_count_sqr = torch.arange(num_atom_pairs, device=device) - index_sqr_offset\n",
    "\n",
    "    # Compute the indices for the pairs of atoms (using division and mod)\n",
    "    # If the systems get too large this apporach could run into numerical precision issues\n",
    "    index1 = (torch.div(atom_count_sqr, num_atoms_per_image_expand, rounding_mode=\"floor\")) + index_offset_expand\n",
    "    index2 = (atom_count_sqr % num_atoms_per_image_expand) + index_offset_expand\n",
    "    # Get the positions for each atom\n",
    "    pos1 = torch.index_select(atom_pos, 0, index1)\n",
    "    pos2 = torch.index_select(atom_pos, 0, index2)\n",
    "\n",
    "    # Calculate required number of unit cells in each direction.\n",
    "    # Smallest distance between planes separated by a1 is\n",
    "    # 1 / ||(a2 x a3) / V||_2, since a2 x a3 is the area of the plane.\n",
    "    # Note that the unit cell volume V = a1 * (a2 x a3) and that\n",
    "    # (a2 x a3) / V is also the reciprocal primitive vector\n",
    "    # (crystallographer's definition).\n",
    "\n",
    "    cross_a2a3 = torch.cross(data.cell[:, 1], data.cell[:, 2], dim=-1)\n",
    "    cell_vol = torch.sum(data.cell[:, 0] * cross_a2a3, dim=-1, keepdim=True)\n",
    "\n",
    "    if pbc[0]:\n",
    "        inv_min_dist_a1 = torch.norm(cross_a2a3 / cell_vol, p=2, dim=-1)\n",
    "        rep_a1 = torch.ceil(radius * inv_min_dist_a1)\n",
    "    else:\n",
    "        rep_a1 = data.cell.new_zeros(1)\n",
    "\n",
    "    if pbc[1]:\n",
    "        cross_a3a1 = torch.cross(data.cell[:, 2], data.cell[:, 0], dim=-1)\n",
    "        inv_min_dist_a2 = torch.norm(cross_a3a1 / cell_vol, p=2, dim=-1)\n",
    "        rep_a2 = torch.ceil(radius * inv_min_dist_a2)\n",
    "    else:\n",
    "        rep_a2 = data.cell.new_zeros(1)\n",
    "\n",
    "    if pbc[2]:\n",
    "        cross_a1a2 = torch.cross(data.cell[:, 0], data.cell[:, 1], dim=-1)\n",
    "        inv_min_dist_a3 = torch.norm(cross_a1a2 / cell_vol, p=2, dim=-1)\n",
    "        rep_a3 = torch.ceil(radius * inv_min_dist_a3)\n",
    "    else:\n",
    "        rep_a3 = data.cell.new_zeros(1)\n",
    "\n",
    "    # Take the max over all images for uniformity. This is essentially padding.\n",
    "    # Note that this can significantly increase the number of computed distances\n",
    "    # if the required repetitions are very different between images\n",
    "    # (which they usually are). Changing this to sparse (scatter) operations\n",
    "    # might be worth the effort if this function becomes a bottleneck.\n",
    "    max_rep = [rep_a1.max(), rep_a2.max(), rep_a3.max()]\n",
    "\n",
    "    # Tensor of unit cells\n",
    "    cells_per_dim = [torch.arange(-rep, rep + 1, device=device, dtype=torch.float) for rep in max_rep]\n",
    "    unit_cell = torch.cartesian_prod(*cells_per_dim)\n",
    "    num_cells = len(unit_cell)\n",
    "    unit_cell_per_atom = unit_cell.view(1, num_cells, 3).repeat(len(index2), 1, 1)\n",
    "    unit_cell = torch.transpose(unit_cell, 0, 1)\n",
    "    unit_cell_batch = unit_cell.view(1, 3, num_cells).expand(batch_size, -1, -1)\n",
    "\n",
    "    # Compute the x, y, z positional offsets for each cell in each image\n",
    "    data_cell = torch.transpose(data.cell, 1, 2)\n",
    "    pbc_offsets = torch.bmm(data_cell, unit_cell_batch)\n",
    "    pbc_offsets_per_atom = torch.repeat_interleave(pbc_offsets, num_atoms_per_image_sqr, dim=0)\n",
    "\n",
    "    # Expand the positions and indices for the 9 cells\n",
    "    pos1 = pos1.view(-1, 3, 1).expand(-1, -1, num_cells)\n",
    "    pos2 = pos2.view(-1, 3, 1).expand(-1, -1, num_cells)\n",
    "    index1 = index1.view(-1, 1).repeat(1, num_cells).view(-1)\n",
    "    index2 = index2.view(-1, 1).repeat(1, num_cells).view(-1)\n",
    "    # Add the PBC offsets for the second atom\n",
    "    pos2 = pos2 + pbc_offsets_per_atom\n",
    "\n",
    "    # Compute the squared distance between atoms\n",
    "    atom_distance_sqr = torch.sum((pos1 - pos2) ** 2, dim=1)\n",
    "    atom_distance_sqr = atom_distance_sqr.view(-1)\n",
    "\n",
    "    # Remove pairs that are too far apart\n",
    "    mask_within_radius = torch.le(atom_distance_sqr, radius * radius)\n",
    "    # Remove pairs with the same atoms (distance = 0.0)\n",
    "    mask_not_same = torch.gt(atom_distance_sqr, 0.0001)\n",
    "    mask = torch.logical_and(mask_within_radius, mask_not_same)\n",
    "    index1 = torch.masked_select(index1, mask)\n",
    "    index2 = torch.masked_select(index2, mask)\n",
    "    unit_cell = torch.masked_select(unit_cell_per_atom.view(-1, 3), mask.view(-1, 1).expand(-1, 3))\n",
    "    unit_cell = unit_cell.view(-1, 3)\n",
    "    atom_distance_sqr = torch.masked_select(atom_distance_sqr, mask)\n",
    "\n",
    "    # Remove due to errors with jvps\n",
    "#     mask_num_neighbors, num_neighbors_image = get_max_neighbors_mask(\n",
    "#         natoms=data.natoms,\n",
    "#         index=index1,\n",
    "#         atom_distance=atom_distance_sqr,\n",
    "#         max_num_neighbors_threshold=max_num_neighbors_threshold,\n",
    "#     )\n",
    "    num_neighbors_image = torch.tensor(len(index1)).long().to(device)\n",
    "\n",
    "#     if not torch.all(mask_num_neighbors):\n",
    "#         # Mask out the atoms to ensure each atom has at most max_num_neighbors_threshold neighbors\n",
    "#         index1 = torch.masked_select(index1, mask_num_neighbors)\n",
    "#         index2 = torch.masked_select(index2, mask_num_neighbors)\n",
    "#         unit_cell = torch.masked_select(unit_cell.view(-1, 3), mask_num_neighbors.view(-1, 1).expand(-1, 3))\n",
    "#         unit_cell = unit_cell.view(-1, 3)\n",
    "    #unit_cell = unit_cell.view(-1, 3)\n",
    "    edge_index = torch.stack((index2, index1))\n",
    "\n",
    "    return edge_index, unit_cell, num_neighbors_image\n",
    "\n",
    "# def get_max_neighbors_mask(natoms, index, atom_distance, max_num_neighbors_threshold):\n",
    "#     \"\"\"\n",
    "#     Give a mask that filters out edges so that each atom has at most\n",
    "#     `max_num_neighbors_threshold` neighbors.\n",
    "#     Assumes that `index` is sorted.\n",
    "#     \"\"\"\n",
    "#     device = natoms.device\n",
    "#     num_atoms = natoms.sum()\n",
    "\n",
    "#     # Get number of neighbors\n",
    "#     # segment_coo assumes sorted index\n",
    "#     ones = index.new_ones(1).expand_as(index)\n",
    "#     num_neighbors = segment_coo(ones, index, dim_size=num_atoms)\n",
    "#     max_num_neighbors = num_neighbors.max()\n",
    "#     num_neighbors_thresholded = num_neighbors.clamp(max=max_num_neighbors_threshold)\n",
    "\n",
    "#     # Get number of (thresholded) neighbors per image\n",
    "#     image_indptr = torch.zeros(natoms.shape[0] + 1, device=device, dtype=torch.long)\n",
    "#     image_indptr[1:] = torch.cumsum(natoms, dim=0)\n",
    "#     num_neighbors_image = segment_csr(num_neighbors_thresholded, image_indptr)\n",
    "\n",
    "#     # If max_num_neighbors is below the threshold, return early\n",
    "#     if max_num_neighbors <= max_num_neighbors_threshold or max_num_neighbors_threshold <= 0:\n",
    "#         mask_num_neighbors = torch.tensor([True], dtype=bool, device=device).expand_as(index)\n",
    "#         return mask_num_neighbors, num_neighbors_image\n",
    "\n",
    "#     # Create a tensor of size [num_atoms, max_num_neighbors] to sort the distances of the neighbors.\n",
    "#     # Fill with infinity so we can easily remove unused distances later.\n",
    "#     distance_sort = torch.full([num_atoms * max_num_neighbors], np.inf, device=device)\n",
    "\n",
    "#     # Create an index map to map distances from atom_distance to distance_sort\n",
    "#     # index_sort_map assumes index to be sorted\n",
    "#     index_neighbor_offset = torch.cumsum(num_neighbors, dim=0) - num_neighbors\n",
    "#     index_neighbor_offset_expand = torch.repeat_interleave(index_neighbor_offset, num_neighbors)\n",
    "#     index_sort_map = index * max_num_neighbors + torch.arange(len(index), device=device) - index_neighbor_offset_expand\n",
    "#     distance_sort.index_copy_(0, index_sort_map, atom_distance)\n",
    "#     distance_sort = distance_sort.view(num_atoms, max_num_neighbors)\n",
    "\n",
    "#     # Sort neighboring atoms based on distance\n",
    "#     distance_sort, index_sort = torch.sort(distance_sort, dim=1)\n",
    "#     # Select the max_num_neighbors_threshold neighbors that are closest\n",
    "#     distance_sort = distance_sort[:, :max_num_neighbors_threshold]\n",
    "#     index_sort = index_sort[:, :max_num_neighbors_threshold]\n",
    "\n",
    "#     # Offset index_sort so that it indexes into index\n",
    "#     index_sort = index_sort + index_neighbor_offset.view(-1, 1).expand(-1, max_num_neighbors_threshold)\n",
    "#     # Remove \"unused pairs\" with infinite distances\n",
    "#     mask_finite = torch.isfinite(distance_sort)\n",
    "#     index_sort = torch.masked_select(index_sort, mask_finite)\n",
    "\n",
    "#     # At this point index_sort contains the index into index of the\n",
    "#     # closest max_num_neighbors_threshold neighbors per atom\n",
    "#     # Create a mask to remove all pairs not in index_sort\n",
    "#     mask_num_neighbors = torch.zeros(len(index), device=device, dtype=bool)\n",
    "#     mask_num_neighbors.index_fill_(0, index_sort, True)\n",
    "\n",
    "#     return mask_num_neighbors, num_neighbors_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf220825",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Batch.from_data_list(data_batch[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, cell_offsets, neighbors = my_radius_graph_pbc(data, 6.0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_pbc_distances(\n",
    "    data.pos,\n",
    "    edge_index,\n",
    "    data.cell,\n",
    "    cell_offsets,\n",
    "    neighbors,\n",
    "    return_offsets=True,\n",
    "    return_distance_vec=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ce94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_offsets, neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d626a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.common.utils import get_max_neighbors_mask, get_pbc_distances, radius_graph_pbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539af0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index1, cell_offsets1, neighbors1 = radius_graph_pbc(data, 6.0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64507a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = get_pbc_distances(\n",
    "    data.pos,\n",
    "    edge_index1,\n",
    "    data.cell,\n",
    "    cell_offsets1,\n",
    "    neighbors1,\n",
    "    return_offsets=True,\n",
    "    return_distance_vec=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b058dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(edge_index, edge_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c3d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(cell_offsets, cell_offsets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28104f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(neighbors, neighbors1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = []\n",
    "for key in out.keys():\n",
    "    trues.append(torch.equal(out[key], out1[key]))\n",
    "print(all(trues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import radius_graph\n",
    "\n",
    "from ocpmodels.common.utils import (\n",
    "    compute_neighbors,\n",
    "    conditional_grad,\n",
    "    get_pbc_distances,\n",
    "    radius_graph_pbc,\n",
    ")\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_atoms=None, bond_feat_dim=None, num_targets=None):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.num_atoms = num_atoms\n",
    "        self.bond_feat_dim = bond_feat_dim\n",
    "        self.num_targets = num_targets\n",
    "\n",
    "    def forward(self, data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate_graph(\n",
    "        self,\n",
    "        data,\n",
    "        cutoff=None,\n",
    "        max_neighbors=None,\n",
    "        use_pbc=None,\n",
    "        otf_graph=None,\n",
    "    ):\n",
    "        cutoff = cutoff or self.cutoff\n",
    "        max_neighbors = max_neighbors or self.max_neighbors\n",
    "        use_pbc = use_pbc or self.use_pbc\n",
    "        otf_graph = otf_graph or self.otf_graph\n",
    "\n",
    "        if not otf_graph:\n",
    "            try:\n",
    "                edge_index = data.edge_index\n",
    "\n",
    "                if use_pbc:\n",
    "                    cell_offsets = data.cell_offsets\n",
    "                    neighbors = data.neighbors\n",
    "\n",
    "            except AttributeError:\n",
    "                logging.warning(\"Turning otf_graph=True as required attributes not present in data object\")\n",
    "                otf_graph = True\n",
    "\n",
    "        if use_pbc:\n",
    "            if otf_graph:\n",
    "                edge_index, cell_offsets, neighbors = my_radius_graph_pbc(data, cutoff, max_neighbors)\n",
    "\n",
    "            out = get_pbc_distances(\n",
    "                data.pos,\n",
    "                edge_index,\n",
    "                data.cell,\n",
    "                cell_offsets,\n",
    "                neighbors,\n",
    "                return_offsets=True,\n",
    "                return_distance_vec=True,\n",
    "            )\n",
    "\n",
    "            edge_index = out[\"edge_index\"]\n",
    "            edge_dist = out[\"distances\"]\n",
    "            cell_offset_distances = out[\"offsets\"]\n",
    "            distance_vec = out[\"distance_vec\"]\n",
    "        else:\n",
    "            if otf_graph:\n",
    "                edge_index = radius_graph(\n",
    "                    data.pos,\n",
    "                    r=cutoff,\n",
    "                    batch=data.batch,\n",
    "                    max_num_neighbors=max_neighbors,\n",
    "                )\n",
    "\n",
    "            j, i = edge_index\n",
    "            distance_vec = data.pos[j] - data.pos[i]\n",
    "\n",
    "            edge_dist = distance_vec.norm(dim=-1)\n",
    "            cell_offsets = torch.zeros(edge_index.shape[1], 3, device=data.pos.device)\n",
    "            cell_offset_distances = torch.zeros_like(cell_offsets, device=data.pos.device)\n",
    "            neighbors = compute_neighbors(data, edge_index)\n",
    "\n",
    "        return (\n",
    "            edge_index,\n",
    "            edge_dist,\n",
    "            distance_vec,\n",
    "            cell_offsets,\n",
    "            cell_offset_distances,\n",
    "            neighbors,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Facebook, Inc. and its affiliates.\n",
    "\n",
    "This source code is licensed under the MIT license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import SchNet\n",
    "from torch_scatter import scatter\n",
    "\n",
    "from ocpmodels.common.registry import registry\n",
    "from ocpmodels.common.utils import (\n",
    "    conditional_grad,\n",
    "    get_pbc_distances,\n",
    "    radius_graph_pbc,\n",
    ")\n",
    "#from ocpmodels.models.base import BaseModel\n",
    "\n",
    "\n",
    "@registry.register_model(\"schnet\")\n",
    "class SchNetWrap(SchNet, BaseModel):\n",
    "    r\"\"\"Wrapper around the continuous-filter convolutional neural network SchNet from the\n",
    "    `\"SchNet: A Continuous-filter Convolutional Neural Network for Modeling\n",
    "    Quantum Interactions\" <https://arxiv.org/abs/1706.08566>`_. Each layer uses interaction\n",
    "    block of the form:\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{x}_j \\odot\n",
    "        h_{\\mathbf{\\Theta}} ( \\exp(-\\gamma(\\mathbf{e}_{j,i} - \\mathbf{\\mu}))),\n",
    "\n",
    "    Args:\n",
    "        num_atoms (int): Unused argument\n",
    "        bond_feat_dim (int): Unused argument\n",
    "        num_targets (int): Number of targets to predict.\n",
    "        representation (bool, optional): If set to :obj:`True`, the model will output intermediate representation output\n",
    "            from the 'representation_layer' interaction block. (default: :obj:`False`)\n",
    "        representation_layer (int, optional): The interaction block to output the representation from.\n",
    "        use_pbc (bool, optional): If set to :obj:`True`, account for periodic boundary conditions.\n",
    "            (default: :obj:`True`)\n",
    "        regress_forces (bool, optional): If set to :obj:`True`, predict forces by differentiating\n",
    "            energy with respect to positions.\n",
    "            (default: :obj:`True`)\n",
    "        otf_graph (bool, optional): If set to :obj:`True`, compute graph edges on the fly.\n",
    "            (default: :obj:`False`)\n",
    "        hidden_channels (int, optional): Number of hidden channels.\n",
    "            (default: :obj:`128`)\n",
    "        num_filters (int, optional): Number of filters to use.\n",
    "            (default: :obj:`128`)\n",
    "        num_interactions (int, optional): Number of interaction blocks\n",
    "            (default: :obj:`6`)\n",
    "        num_gaussians (int, optional): The number of gaussians :math:`\\mu`.\n",
    "            (default: :obj:`50`)\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        readout (string, optional): Whether to apply :obj:`\"add\"` or\n",
    "            :obj:`\"mean\"` global aggregation. (default: :obj:`\"add\"`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_atoms,  # not used\n",
    "        bond_feat_dim,  # not used\n",
    "        num_targets,\n",
    "        representation=False,\n",
    "        representation_layer=None,\n",
    "        use_pbc=True,\n",
    "        regress_forces=True,\n",
    "        otf_graph=False,\n",
    "        hidden_channels=6,\n",
    "        num_filters=12,\n",
    "        num_interactions=6,\n",
    "        num_gaussians=5,\n",
    "        cutoff=6.0,\n",
    "        readout=\"add\",\n",
    "        mekrr_forces=False,\n",
    "    ):\n",
    "        self.num_targets = num_targets\n",
    "        self.representation = representation\n",
    "        self.representation_layer = representation_layer\n",
    "        self.regress_forces = regress_forces\n",
    "        self.use_pbc = use_pbc\n",
    "        self.cutoff = cutoff\n",
    "        self.otf_graph = otf_graph\n",
    "        self.max_neighbors = 10000000\n",
    "        self.reduce = readout\n",
    "        self.mekrr_forces = mekrr_forces\n",
    "        super(SchNetWrap, self).__init__(\n",
    "            hidden_channels=hidden_channels,\n",
    "            num_filters=num_filters,\n",
    "            num_interactions=num_interactions,\n",
    "            num_gaussians=num_gaussians,\n",
    "            cutoff=cutoff,\n",
    "            readout=readout,\n",
    "        )\n",
    "        # Added by: Isak Falk\n",
    "        # If using the model as representation we output the intermediate layer\n",
    "        if self.representation:\n",
    "            self.interactions = self.interactions[: self.representation_layer]\n",
    "\n",
    "    @conditional_grad(torch.enable_grad())\n",
    "    def _forward(self, data):\n",
    "        z = data.atomic_numbers.long()\n",
    "        pos = data.pos\n",
    "        batch = data.batch\n",
    "\n",
    "        (\n",
    "            edge_index,\n",
    "            edge_weight,\n",
    "            distance_vec,\n",
    "            cell_offsets,\n",
    "            _,  # cell offset distances\n",
    "            neighbors,\n",
    "        ) = self.generate_graph(\n",
    "            data\n",
    "        )  # See the BaseModel.generate_graph method for more details\n",
    "\n",
    "        # Added by: Isak Falk\n",
    "        # Intermediate representation only works for self.use_pbc=True\n",
    "        if self.use_pbc:\n",
    "            assert z.dim() == 1 and z.dtype == torch.long\n",
    "\n",
    "            edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "            h = self.embedding(z)\n",
    "            # For potential representation output\n",
    "            for interaction in self.interactions:\n",
    "                h = h + interaction(h, edge_index, edge_weight, edge_attr)\n",
    "            if self.representation:\n",
    "                return h\n",
    "\n",
    "            h = self.lin1(h)\n",
    "            h = self.act(h)\n",
    "            h = self.lin2(h)\n",
    "\n",
    "            batch = torch.zeros_like(z) if batch is None else batch\n",
    "            energy = scatter(h, batch, dim=0, reduce=self.reduce)\n",
    "        else:\n",
    "            # Cannot use this for representation\n",
    "            energy = super(SchNetWrap, self).forward(z, pos, batch)\n",
    "        return energy\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Need to not change the requires_grad of the input for mekrr\n",
    "        if self.regress_forces and not self.mekrr_forces:\n",
    "            data.pos.requires_grad_(True)\n",
    "        energy = self._forward(data)\n",
    "\n",
    "        if self.regress_forces:\n",
    "            forces = -1 * (\n",
    "                torch.autograd.grad(\n",
    "                    energy,\n",
    "                    data.pos,\n",
    "                    grad_outputs=torch.ones_like(energy),\n",
    "                    create_graph=True,\n",
    "                )[0]\n",
    "            )\n",
    "            return energy, forces\n",
    "        else:\n",
    "            return energy\n",
    "\n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a29ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SchNetWrap(num_targets=1, num_atoms=47, bond_feat_dim=50, representation=True, representation_layer=2)\n",
    "model.regress_forces = False\n",
    "model.mekrr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf7e157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 5\n",
    "data = Batch.from_data_list(data_batch[:frames])\n",
    "data.pos.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9919fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "h = model(data)\n",
    "d = h.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02690a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n",
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "frames = 50\n",
    "data = Batch.from_data_list(data_batch[:frames])\n",
    "data.pos.requires_grad = True\n",
    "pos = data.pop(\"pos\")\n",
    "\n",
    "def f(pos, data, model):\n",
    "    pos_list = []\n",
    "    batch_idx = data.batch\n",
    "    batch_unique_idx = torch.unique(batch_idx)\n",
    "    for uidx in batch_unique_idx:\n",
    "        pos_list.append(pos[batch_idx == uidx])\n",
    "\n",
    "    data_list = data.to_data_list()\n",
    "    for i, pos in enumerate(pos_list):\n",
    "        data_list[i].pos = pos\n",
    "\n",
    "    new_batch = Batch.from_data_list(data_list)\n",
    "    h = model(new_batch).reshape(frames, num_atoms, d)\n",
    "    return h\n",
    "\n",
    "y = f(\n",
    "    pos,\n",
    "    data,\n",
    "    model,\n",
    ")\n",
    "m = y.shape[0]\n",
    "gr = torch.autograd.grad(\n",
    "    outputs=y,\n",
    "    inputs=pos,\n",
    "    grad_outputs=torch.ones_like(y),\n",
    "    retain_graph=False,\n",
    "    create_graph=False,\n",
    "    allow_unused=False,\n",
    "    is_grads_batched=False,\n",
    ")[0]\n",
    "gr\n",
    "output, vjp_fn = torch.func.vjp(torch.func.functionalize(lambda x: f(x, data, model)), pos)\n",
    "#_, jvp_fn = torch.func.jvp(lambda x: f(x, data, model), pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7d8a01f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7650e-01,  1.5149e+00, -2.8976e-01,  ...,  1.9644e+00,\n",
       "          -4.1806e-01, -9.0687e-01],\n",
       "         [ 1.3620e-01,  1.6507e+00, -4.3054e-01,  ...,  6.2981e-01,\n",
       "          -9.7201e-02, -1.1375e+00],\n",
       "         [-9.8533e-02,  1.5343e+00, -2.0628e-01,  ...,  1.5074e+00,\n",
       "          -6.5693e-01, -8.4682e-01],\n",
       "         ...,\n",
       "         [-5.1197e-01,  1.5668e+00, -4.0957e-01,  ...,  2.0028e+00,\n",
       "          -3.2623e-01, -8.9610e-01],\n",
       "         [ 2.4639e-01,  6.8669e-01,  4.5762e-01,  ...,  2.2897e+00,\n",
       "          -4.6831e-01, -1.5964e+00],\n",
       "         [-4.6865e-01,  5.8663e-01,  3.4989e-01,  ...,  1.5248e+00,\n",
       "          -2.7791e-01, -1.3841e+00]],\n",
       "\n",
       "        [[-3.1987e-01,  1.5374e+00, -2.9204e-01,  ...,  1.9518e+00,\n",
       "          -4.2553e-01, -8.9740e-01],\n",
       "         [ 6.2852e-02,  1.7195e+00, -3.5327e-01,  ...,  6.3971e-01,\n",
       "          -1.1011e-01, -1.1836e+00],\n",
       "         [-1.7572e-01,  1.4655e+00, -1.7963e-01,  ...,  1.5187e+00,\n",
       "          -6.3084e-01, -8.0103e-01],\n",
       "         ...,\n",
       "         [-5.8822e-01,  1.6023e+00, -4.2870e-01,  ...,  1.9929e+00,\n",
       "          -3.3948e-01, -9.1210e-01],\n",
       "         [ 2.9915e-01,  7.0780e-01,  5.6006e-01,  ...,  2.2815e+00,\n",
       "          -4.0243e-01, -1.7062e+00],\n",
       "         [-4.6917e-01,  6.2003e-01,  3.3965e-01,  ...,  1.5524e+00,\n",
       "          -2.7289e-01, -1.3595e+00]],\n",
       "\n",
       "        [[-3.5433e-01,  1.5223e+00, -2.7969e-01,  ...,  1.9605e+00,\n",
       "          -4.4064e-01, -8.6324e-01],\n",
       "         [-9.6550e-03,  1.7185e+00, -2.7081e-01,  ...,  6.0743e-01,\n",
       "          -1.6919e-01, -1.2315e+00],\n",
       "         [-2.8401e-01,  1.3564e+00, -1.4638e-01,  ...,  1.5190e+00,\n",
       "          -6.0372e-01, -7.3117e-01],\n",
       "         ...,\n",
       "         [-6.6354e-01,  1.5911e+00, -4.5563e-01,  ...,  1.9700e+00,\n",
       "          -3.6183e-01, -8.9451e-01],\n",
       "         [ 2.8093e-01,  7.2184e-01,  5.3020e-01,  ...,  2.1909e+00,\n",
       "          -4.1339e-01, -1.6936e+00],\n",
       "         [-5.0210e-01,  6.4572e-01,  2.7299e-01,  ...,  1.5081e+00,\n",
       "          -3.1990e-01, -1.2089e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.2342e-01,  1.3653e+00, -1.7937e-01,  ...,  1.9468e+00,\n",
       "          -5.8097e-01, -7.9505e-01],\n",
       "         [-4.7829e-01,  5.9031e-01, -6.5969e-02,  ...,  3.9801e-01,\n",
       "           1.8948e-04, -1.1222e+00],\n",
       "         [-5.1191e-01,  1.5520e+00, -3.3016e-01,  ...,  1.7844e+00,\n",
       "          -5.2280e-01, -7.0784e-01],\n",
       "         ...,\n",
       "         [-5.5135e-01,  1.5606e+00, -8.8445e-02,  ...,  2.1086e+00,\n",
       "          -3.5776e-01, -1.0434e+00],\n",
       "         [-7.4021e-01,  2.9123e-02, -1.4665e-02,  ...,  1.4630e+00,\n",
       "          -3.7942e-01, -9.5706e-01],\n",
       "         [ 4.4412e-02,  3.1135e-01,  3.3432e-01,  ...,  2.1206e+00,\n",
       "          -5.5763e-01, -1.2957e+00]],\n",
       "\n",
       "        [[-3.7424e-01,  1.3547e+00, -1.6929e-01,  ...,  1.9087e+00,\n",
       "          -5.7000e-01, -8.0201e-01],\n",
       "         [-5.3726e-01,  4.4958e-01, -1.1327e-01,  ...,  3.7813e-01,\n",
       "           4.0527e-02, -1.0713e+00],\n",
       "         [-4.8198e-01,  1.5587e+00, -3.3675e-01,  ...,  1.8103e+00,\n",
       "          -5.3137e-01, -7.2743e-01],\n",
       "         ...,\n",
       "         [-4.5330e-01,  1.4862e+00, -7.3628e-02,  ...,  2.1064e+00,\n",
       "          -3.4345e-01, -1.0088e+00],\n",
       "         [-7.3414e-01,  8.8926e-02, -9.7190e-03,  ...,  1.4718e+00,\n",
       "          -4.3067e-01, -9.1631e-01],\n",
       "         [ 1.0630e-01,  3.9677e-01,  2.9411e-01,  ...,  2.0208e+00,\n",
       "          -5.7333e-01, -1.1637e+00]],\n",
       "\n",
       "        [[-4.0326e-01,  1.3749e+00, -1.6016e-01,  ...,  1.9015e+00,\n",
       "          -5.5880e-01, -8.0921e-01],\n",
       "         [-5.5952e-01,  3.7625e-01, -1.6005e-01,  ...,  4.0611e-01,\n",
       "           5.6290e-02, -1.0102e+00],\n",
       "         [-4.0919e-01,  1.5983e+00, -3.4703e-01,  ...,  1.8624e+00,\n",
       "          -5.4190e-01, -7.7273e-01],\n",
       "         ...,\n",
       "         [-3.8119e-01,  1.4049e+00, -6.7825e-02,  ...,  2.0902e+00,\n",
       "          -3.1951e-01, -9.7006e-01],\n",
       "         [-6.5988e-01,  1.1870e-01,  1.4836e-01,  ...,  1.5932e+00,\n",
       "          -3.8293e-01, -1.0983e+00],\n",
       "         [ 1.4230e-01,  4.3549e-01,  4.1559e-01,  ...,  2.0045e+00,\n",
       "          -4.2127e-01, -1.2221e+00]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc708119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.2902,   5.1938,  13.4935],\n",
       "        [ 24.6666, -12.7259, -24.2249],\n",
       "        [ -3.8296,  -5.3556,  -7.1037],\n",
       "        ...,\n",
       "        [  1.1242,   2.9582,  35.0233],\n",
       "        [-31.1952, -51.6997,  42.6889],\n",
       "        [  8.8059, 100.3142,  99.7052]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vjp_fn(torch.ones_like(torch.ones_like(y)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8255f367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.2902,   5.1938,  13.4935],\n",
       "        [ 24.6666, -12.7259, -24.2249],\n",
       "        [ -3.8296,  -5.3556,  -7.1037],\n",
       "        ...,\n",
       "        [  1.1242,   2.9582,  35.0233],\n",
       "        [-31.1952, -51.6997,  42.6889],\n",
       "        [  8.8059, 100.3142,  99.7052]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e951196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n",
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The output of the user-provided function is independent of input 0. This is not allowed in strict mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m f(\n\u001b[1;32m      2\u001b[0m     data\u001b[38;5;241m.\u001b[39mpos,\n\u001b[1;32m      3\u001b[0m     data,\n\u001b[1;32m      4\u001b[0m     model,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m gr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\n\u001b[1;32m      7\u001b[0m     outputs\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m      8\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mpos,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     is_grads_batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m func_output, jvp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctionalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmutations_and_views\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/autograd/functional.py:394\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, inputs, v, create_graph, strict)\u001b[0m\n\u001b[1;32m    391\u001b[0m     grad_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mzeros_like(out, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outputs)\n\u001b[1;32m    393\u001b[0m     grad_inputs \u001b[38;5;241m=\u001b[39m _autograd_grad(outputs, inputs, grad_outputs, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 394\u001b[0m     \u001b[43m_check_requires_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_inputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m create_graph:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/autograd/functional.py:124\u001b[0m, in \u001b[0;36m_check_requires_grad\u001b[0;34m(inputs, input_type, strict)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;66;03m# This can only be reached for grad_inputs.\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of the user-provided function is independent of input \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This is not allowed in strict mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inp\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m input_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhessian\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The output of the user-provided function is independent of input 0. This is not allowed in strict mode."
     ]
    }
   ],
   "source": [
    "y = f(\n",
    "    data.pos,\n",
    "    data,\n",
    "    model,\n",
    ")\n",
    "gr = torch.autograd.grad(\n",
    "    outputs=y,\n",
    "    inputs=data.pos,\n",
    "    grad_outputs=torch.ones_like(y),\n",
    "    retain_graph=False,\n",
    "    create_graph=False,\n",
    "    allow_unused=False,\n",
    "    is_grads_batched=False,\n",
    ")[0]\n",
    "\n",
    "\n",
    "func_output, jvp = torch.autograd.functional.jvp(torch.func.functionalize(lambda x: f(x, data, model=model), remove=\"mutations_and_views\"),\n",
    "                                                 data.pos,\n",
    "                                                 v=torch.ones_like(data.pos),\n",
    "                                                 strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fcfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(pos, data):\n",
    "    batch_idx = data.batch\n",
    "    data_list = []\n",
    "    data.pop(\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1ed3abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_idx = data.batch\n",
    "data_list = []\n",
    "batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f796602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 5\n",
    "data = Batch.from_data_list(data_batch[:frames])\n",
    "data.pos.requires_grad = True\n",
    "pos = data.pop(\"pos\")\n",
    "pos_list = []\n",
    "batch_unique_idx = torch.unique(batch_idx)\n",
    "for uidx in batch_unique_idx:\n",
    "    pos_list.append(pos[batch_idx == uidx])\n",
    "\n",
    "data_list = data.to_data_list()\n",
    "for i, pos in enumerate(pos_list):\n",
    "    data_list[i][\"pos\"] = pos\n",
    "\n",
    "new_batch = Batch.from_data_list(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c783530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64d11163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbcbc3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [-2.0273e+00,  1.1828e+00, -1.9011e-01],\n",
       "        [-2.0004e+00, -1.1554e+00, -1.8034e+00],\n",
       "        [-2.0192e+00, -3.4735e+00, -1.0363e+00],\n",
       "        [ 7.2491e-03, -2.4519e+00, -1.1423e-01],\n",
       "        [ 1.4912e-04, -4.6227e+00, -1.7621e+00],\n",
       "        [ 2.0244e+00, -3.4753e+00, -1.0387e+00],\n",
       "        [ 4.0215e+00, -2.3029e+00, -1.8622e-01],\n",
       "        [ 4.0186e+00, -4.6295e+00, -1.7866e+00],\n",
       "        [ 6.0143e+00, -3.4703e+00, -1.0251e+00],\n",
       "        [ 6.0130e+00, -1.1596e+00, -1.7765e+00],\n",
       "        [ 6.0117e+00,  1.1477e+00, -1.8844e-01],\n",
       "        [ 4.0055e+00,  2.3124e+00, -1.7776e+00],\n",
       "        [ 4.0117e+00,  4.6355e+00, -1.8742e-01],\n",
       "        [ 6.0139e+00,  3.4695e+00, -1.0276e+00],\n",
       "        [ 6.0129e+00,  3.4715e+00, -3.3625e+00],\n",
       "        [ 6.0129e+00,  1.1572e+00, -2.5204e+00],\n",
       "        [ 4.0069e+00, -1.3589e-03, -1.0381e+00],\n",
       "        [ 2.0252e+00,  1.1829e+00, -1.8995e-01],\n",
       "        [ 2.0022e+00, -1.1564e+00, -1.8098e+00],\n",
       "        [ 2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [ 6.0129e+00, -3.4715e+00, -3.3631e+00],\n",
       "        [-2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 6.2173e-04,  2.3078e+00, -1.7924e+00],\n",
       "        [ 3.3670e-05,  4.6294e+00, -1.8848e-01],\n",
       "        [ 2.0030e+00,  3.4779e+00, -1.0334e+00],\n",
       "        [ 2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [ 4.0085e+00, -4.7141e-04, -3.3616e+00],\n",
       "        [-2.0015e+00,  3.4785e+00, -1.0340e+00],\n",
       "        [-4.0122e+00,  4.6360e+00, -1.8601e-01],\n",
       "        [-4.0053e+00,  2.3133e+00, -1.7789e+00],\n",
       "        [-4.0063e+00, -8.7427e-04, -1.0374e+00],\n",
       "        [-4.0201e+00, -2.3039e+00, -1.8670e-01],\n",
       "        [-4.0161e+00, -4.6299e+00, -1.7864e+00],\n",
       "        [-2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 0.0000e+00, -2.3143e+00, -2.5200e+00],\n",
       "        [ 6.7344e-04, -1.0660e-02, -9.2293e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.3617e+00],\n",
       "        [-4.0085e+00, -4.7141e-04, -3.3616e+00],\n",
       "        [-4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [-4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 0.0000e+00,  4.6290e+00, -2.5203e+00],\n",
       "        [ 4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 4.6364e-02, -6.2514e-01,  8.1560e-01],\n",
       "        [ 6.9810e-02, -1.3980e+00,  1.7103e+00],\n",
       "        [-2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [-2.0994e+00,  1.2070e+00, -2.3205e-01],\n",
       "        [-2.0702e+00, -1.1864e+00, -1.8439e+00],\n",
       "        [-1.9870e+00, -3.4934e+00, -9.8907e-01],\n",
       "        [ 2.9013e-02, -2.4343e+00, -1.0723e-01],\n",
       "        [ 1.2641e-02, -4.6043e+00, -1.7556e+00],\n",
       "        [ 2.0490e+00, -3.4940e+00, -1.0205e+00],\n",
       "        [ 4.0258e+00, -2.2787e+00, -1.8013e-01],\n",
       "        [ 4.0361e+00, -4.6334e+00, -1.7720e+00],\n",
       "        [ 6.0268e+00, -3.4462e+00, -9.4054e-01],\n",
       "        [ 6.0626e+00, -1.1484e+00, -1.7686e+00],\n",
       "        [ 6.0413e+00,  1.1487e+00, -2.0789e-01],\n",
       "        [ 3.9756e+00,  2.4229e+00, -1.7804e+00],\n",
       "        [ 3.9592e+00,  4.5950e+00, -2.1532e-01],\n",
       "        [ 6.0156e+00,  3.4724e+00, -1.0506e+00],\n",
       "        [ 6.0129e+00,  3.4715e+00, -3.3625e+00],\n",
       "        [ 6.0129e+00,  1.1572e+00, -2.5204e+00],\n",
       "        [ 4.0125e+00, -8.5807e-03, -1.0422e+00],\n",
       "        [ 2.0097e+00,  1.2238e+00, -2.5166e-01],\n",
       "        [ 1.9937e+00, -1.1109e+00, -1.7948e+00],\n",
       "        [ 2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [ 6.0129e+00, -3.4715e+00, -3.3631e+00],\n",
       "        [-2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.2371e-02,  2.2495e+00, -1.8267e+00],\n",
       "        [ 7.6963e-02,  4.6305e+00, -2.2184e-01],\n",
       "        [ 2.0336e+00,  3.4550e+00, -9.8098e-01],\n",
       "        [ 2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [ 4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-2.0238e+00,  3.4378e+00, -1.0448e+00],\n",
       "        [-4.0786e+00,  4.6789e+00, -1.7260e-01],\n",
       "        [-4.0327e+00,  2.2745e+00, -1.7585e+00],\n",
       "        [-4.0557e+00,  1.1591e-03, -1.0089e+00],\n",
       "        [-4.0365e+00, -2.3027e+00, -1.7660e-01],\n",
       "        [-4.0220e+00, -4.6161e+00, -1.7262e+00],\n",
       "        [-2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 0.0000e+00, -2.3143e+00, -2.5200e+00],\n",
       "        [-6.6728e-02, -5.0353e-02, -8.2522e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.3617e+00],\n",
       "        [-4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [-4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 0.0000e+00,  4.6290e+00, -2.5203e+00],\n",
       "        [ 4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [-6.0552e-04, -6.0749e-01,  8.4271e-01],\n",
       "        [ 1.3307e-02, -1.3930e+00,  1.7444e+00],\n",
       "        [-2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [-2.1802e+00,  1.2291e+00, -2.6864e-01],\n",
       "        [-2.1355e+00, -1.2163e+00, -1.8842e+00],\n",
       "        [-1.9557e+00, -3.5115e+00, -9.4067e-01],\n",
       "        [ 5.6211e-02, -2.4206e+00, -9.6269e-02],\n",
       "        [ 2.6866e-02, -4.5865e+00, -1.7496e+00],\n",
       "        [ 2.0751e+00, -3.5055e+00, -1.0048e+00],\n",
       "        [ 4.0293e+00, -2.2518e+00, -1.7208e-01],\n",
       "        [ 4.0574e+00, -4.6376e+00, -1.7551e+00],\n",
       "        [ 6.0356e+00, -3.4212e+00, -8.5723e-01],\n",
       "        [ 6.1030e+00, -1.1416e+00, -1.7608e+00],\n",
       "        [ 6.0701e+00,  1.1527e+00, -2.2444e-01],\n",
       "        [ 3.9499e+00,  2.5184e+00, -1.7856e+00],\n",
       "        [ 3.9068e+00,  4.5525e+00, -2.3656e-01],\n",
       "        [ 6.0167e+00,  3.4786e+00, -1.0727e+00],\n",
       "        [ 6.0129e+00,  3.4715e+00, -3.3625e+00],\n",
       "        [ 6.0129e+00,  1.1572e+00, -2.5204e+00],\n",
       "        [ 4.0222e+00, -7.0594e-03, -1.0512e+00],\n",
       "        [ 1.9906e+00,  1.2593e+00, -3.0717e-01],\n",
       "        [ 1.9810e+00, -1.0704e+00, -1.7757e+00],\n",
       "        [ 2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [ 6.0129e+00, -3.4715e+00, -3.3631e+00],\n",
       "        [-2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 4.2449e-02,  2.1934e+00, -1.8613e+00],\n",
       "        [ 1.5810e-01,  4.6295e+00, -2.5365e-01],\n",
       "        [ 2.0530e+00,  3.4381e+00, -9.3629e-01],\n",
       "        [ 2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [ 4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-2.0448e+00,  3.4040e+00, -1.0579e+00],\n",
       "        [-4.1511e+00,  4.7231e+00, -1.5856e-01],\n",
       "        [-4.0605e+00,  2.2386e+00, -1.7388e+00],\n",
       "        [-4.0997e+00, -9.4966e-04, -9.7966e-01],\n",
       "        [-4.0498e+00, -2.3015e+00, -1.6302e-01],\n",
       "        [-4.0273e+00, -4.6037e+00, -1.6584e+00],\n",
       "        [-2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 0.0000e+00, -2.3143e+00, -2.5200e+00],\n",
       "        [-1.4212e-01, -8.0043e-02, -7.4887e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.3617e+00],\n",
       "        [-4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [-4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 0.0000e+00,  4.6290e+00, -2.5203e+00],\n",
       "        [ 4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [-5.6818e-02, -6.1408e-01,  9.4738e-01],\n",
       "        [-4.8382e-02, -1.3936e+00,  1.7913e+00],\n",
       "        [-2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [-2.2772e+00,  1.2469e+00, -2.9074e-01],\n",
       "        [-2.1879e+00, -1.2424e+00, -1.9233e+00],\n",
       "        [-1.9266e+00, -3.5257e+00, -8.9015e-01],\n",
       "        [ 9.5491e-02, -2.4128e+00, -7.6699e-02],\n",
       "        [ 4.3734e-02, -4.5699e+00, -1.7455e+00],\n",
       "        [ 2.1045e+00, -3.5019e+00, -9.9470e-01],\n",
       "        [ 4.0301e+00, -2.2182e+00, -1.6001e-01],\n",
       "        [ 4.0852e+00, -4.6417e+00, -1.7343e+00],\n",
       "        [ 6.0365e+00, -3.3957e+00, -7.7610e-01],\n",
       "        [ 6.1225e+00, -1.1450e+00, -1.7547e+00],\n",
       "        [ 6.0948e+00,  1.1641e+00, -2.3271e-01],\n",
       "        [ 3.9336e+00,  2.5779e+00, -1.7970e+00],\n",
       "        [ 3.8590e+00,  4.5102e+00, -2.3997e-01],\n",
       "        [ 6.0160e+00,  3.4908e+00, -1.0914e+00],\n",
       "        [ 6.0129e+00,  3.4715e+00, -3.3625e+00],\n",
       "        [ 6.0129e+00,  1.1572e+00, -2.5204e+00],\n",
       "        [ 4.0392e+00,  1.0735e-02, -1.0685e+00],\n",
       "        [ 1.9643e+00,  1.2800e+00, -3.4643e-01],\n",
       "        [ 1.9606e+00, -1.0406e+00, -1.7483e+00],\n",
       "        [ 2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [ 6.0129e+00, -3.4715e+00, -3.3631e+00],\n",
       "        [-2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 5.6863e-02,  2.1442e+00, -1.8961e+00],\n",
       "        [ 2.4320e-01,  4.6258e+00, -2.7809e-01],\n",
       "        [ 2.0483e+00,  3.4326e+00, -9.1102e-01],\n",
       "        [ 2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [ 4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-2.0621e+00,  3.3857e+00, -1.0753e+00],\n",
       "        [-4.2358e+00,  4.7694e+00, -1.4220e-01],\n",
       "        [-4.0884e+00,  2.2109e+00, -1.7226e+00],\n",
       "        [-4.1294e+00, -1.2743e-02, -9.4997e-01],\n",
       "        [-4.0553e+00, -2.2998e+00, -1.4178e-01],\n",
       "        [-4.0305e+00, -4.5922e+00, -1.5779e+00],\n",
       "        [-2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 0.0000e+00, -2.3143e+00, -2.5200e+00],\n",
       "        [-2.3388e-01, -9.5531e-02, -6.9899e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.3617e+00],\n",
       "        [-4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [-4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 0.0000e+00,  4.6290e+00, -2.5203e+00],\n",
       "        [ 4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [-1.3105e-01, -6.0563e-01,  1.0909e+00],\n",
       "        [-1.1927e-01, -1.4589e+00,  1.9240e+00],\n",
       "        [-2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [-2.3872e+00,  1.2585e+00, -2.8472e-01],\n",
       "        [-2.2113e+00, -1.2580e+00, -1.9556e+00],\n",
       "        [-1.9035e+00, -3.5325e+00, -8.4145e-01],\n",
       "        [ 1.4961e-01, -2.4087e+00, -4.2858e-02],\n",
       "        [ 6.0917e-02, -4.5558e+00, -1.7459e+00],\n",
       "        [ 2.1363e+00, -3.4770e+00, -9.9424e-01],\n",
       "        [ 4.0257e+00, -2.1754e+00, -1.4346e-01],\n",
       "        [ 4.1178e+00, -4.6434e+00, -1.7110e+00],\n",
       "        [ 6.0257e+00, -3.3736e+00, -7.0573e-01],\n",
       "        [ 6.1076e+00, -1.1634e+00, -1.7526e+00],\n",
       "        [ 6.1089e+00,  1.1868e+00, -2.2531e-01],\n",
       "        [ 3.9328e+00,  2.5738e+00, -1.8166e+00],\n",
       "        [ 3.8266e+00,  4.4758e+00, -2.1331e-01],\n",
       "        [ 6.0100e+00,  3.5093e+00, -1.1017e+00],\n",
       "        [ 6.0129e+00,  3.4715e+00, -3.3625e+00],\n",
       "        [ 6.0129e+00,  1.1572e+00, -2.5204e+00],\n",
       "        [ 4.0630e+00,  4.9045e-02, -1.0939e+00],\n",
       "        [ 1.9299e+00,  1.2744e+00, -3.5514e-01],\n",
       "        [ 1.9323e+00, -1.0293e+00, -1.7104e+00],\n",
       "        [ 2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [ 6.0129e+00, -3.4715e+00, -3.3631e+00],\n",
       "        [-2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 5.8243e-02,  2.1134e+00, -1.9272e+00],\n",
       "        [ 3.1684e-01,  4.6210e+00, -2.8161e-01],\n",
       "        [ 2.0126e+00,  3.4376e+00, -9.2338e-01],\n",
       "        [ 2.0038e+00,  3.4717e+00, -3.3616e+00],\n",
       "        [ 2.0042e+00,  1.1571e+00, -2.5200e+00],\n",
       "        [ 4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-2.0715e+00,  3.3924e+00, -1.0955e+00],\n",
       "        [-4.3301e+00,  4.8152e+00, -1.2239e-01],\n",
       "        [-4.1134e+00,  2.2009e+00, -1.7156e+00],\n",
       "        [-4.1348e+00, -3.9852e-02, -9.2584e-01],\n",
       "        [-4.0464e+00, -2.2977e+00, -1.1061e-01],\n",
       "        [-4.0277e+00, -4.5792e+00, -1.4898e+00],\n",
       "        [-2.0047e+00, -3.4712e+00, -3.3616e+00],\n",
       "        [ 0.0000e+00, -2.3143e+00, -2.5200e+00],\n",
       "        [-3.4028e-01, -9.9744e-02, -6.6466e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.3617e+00],\n",
       "        [-4.0085e+00, -4.7100e-04, -3.3616e+00],\n",
       "        [-4.0089e+00, -2.3145e+00, -2.5203e+00],\n",
       "        [-4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [ 0.0000e+00,  4.6290e+00, -2.5203e+00],\n",
       "        [ 4.0086e+00,  4.6287e+00, -2.5204e+00],\n",
       "        [-2.2568e-01, -6.5304e-01,  1.2785e+00],\n",
       "        [-1.9763e-01, -1.5247e+00,  2.0562e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab592b70",
   "metadata": {},
   "source": [
    "## LinOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be311f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_op00(c0, data, kernel):\n",
    "    pass\n",
    "\n",
    "def lin_op01(c1, data, kernel):\n",
    "    pass\n",
    "\n",
    "def lin_op10(c0, data, kernel):\n",
    "    pass\n",
    "\n",
    "def lin_op11(c1, data, kernel):\n",
    "    pass\n",
    "\n",
    "def lin_op(c0, c1, data, kernel):\n",
    "    _c0 = lin_op00(c0) + lin_op(c1)\n",
    "    _c1 = lin_op10(c0) + lin_op(c1)\n",
    "    return _c0, _c1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
