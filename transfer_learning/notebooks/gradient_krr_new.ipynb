{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f713c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch, Data\n",
    "import functorch\n",
    "import copy\n",
    "from ocpmodels.transfer_learning.models.distribution_regression import (\n",
    "    GaussianKernel,\n",
    "    KernelMeanEmbeddingRidgeRegression,\n",
    "    LinearMeanEmbeddingKernel,\n",
    "    StandardizedOutputRegression,\n",
    "    median_heuristic,\n",
    ")\n",
    "\n",
    "from ocpmodels.transfer_learning.common.utils import (\n",
    "    ATOMS_TO_GRAPH_KWARGS,\n",
    "    load_xyz_to_pyg_batch,\n",
    "    load_xyz_to_pyg_data,\n",
    ")\n",
    "from ocpmodels.transfer_learning.loaders import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a305a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isak/life/references/projects/src/python_lang/ocp\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8284d",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d2acdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isak/life/references/projects/src/python_lang/ocp/ocpmodels/preprocessing/atoms_to_graphs.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  cell = torch.Tensor(atoms.get_cell()).view(1, 3, 3)\n",
      "WARNING:root:Error(s) in loading state_dict for SchNetWrap:\n",
      "\tUnexpected key(s) in state_dict: \"atomic_mass\", \"interactions.2.mlp.0.weight\", \"interactions.2.mlp.0.bias\", \"interactions.2.mlp.2.weight\", \"interactions.2.mlp.2.bias\", \"interactions.2.conv.lin1.weight\", \"interactions.2.conv.lin2.weight\", \"interactions.2.conv.lin2.bias\", \"interactions.2.conv.nn.0.weight\", \"interactions.2.conv.nn.0.bias\", \"interactions.2.conv.nn.2.weight\", \"interactions.2.conv.nn.2.bias\", \"interactions.2.lin.weight\", \"interactions.2.lin.bias\", \"interactions.3.mlp.0.weight\", \"interactions.3.mlp.0.bias\", \"interactions.3.mlp.2.weight\", \"interactions.3.mlp.2.bias\", \"interactions.3.conv.lin1.weight\", \"interactions.3.conv.lin2.weight\", \"interactions.3.conv.lin2.bias\", \"interactions.3.conv.nn.0.weight\", \"interactions.3.conv.nn.0.bias\", \"interactions.3.conv.nn.2.weight\", \"interactions.3.conv.nn.2.bias\", \"interactions.3.lin.weight\", \"interactions.3.lin.bias\", \"interactions.4.mlp.0.weight\", \"interactions.4.mlp.0.bias\", \"interactions.4.mlp.2.weight\", \"interactions.4.mlp.2.bias\", \"interactions.4.conv.lin1.weight\", \"interactions.4.conv.lin2.weight\", \"interactions.4.conv.lin2.bias\", \"interactions.4.conv.nn.0.weight\", \"interactions.4.conv.nn.0.bias\", \"interactions.4.conv.nn.2.weight\", \"interactions.4.conv.nn.2.bias\", \"interactions.4.lin.weight\", \"interactions.4.lin.bias\". \n"
     ]
    }
   ],
   "source": [
    "#%cd ../..\n",
    "### Load checkpoint\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/s2ef_efwt/all/schnet/schnet_all_large.pt\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "\n",
    "### Load data\n",
    "DATA_PATH = Path(\"data/luigi/example-traj-Fe-N2-111.xyz\")\n",
    "raw_data, data_batch, num_frames, num_atoms = load_xyz_to_pyg_batch(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "raw_data, data_list, num_frames, num_atoms = load_xyz_to_pyg_data(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "representation_layer = 2\n",
    "base_loader = BaseLoader(\n",
    "    checkpoint[\"config\"],\n",
    "    representation=True,\n",
    "    representation_kwargs={\n",
    "        \"representation_layer\": representation_layer,\n",
    "    },\n",
    ")\n",
    "base_loader.load_checkpoint(CHECKPOINT_PATH, strict_load=False)\n",
    "model = base_loader.model\n",
    "model.to(device)\n",
    "model.mekrr_forces = True\n",
    "model.regress_forces = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba131d",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3a990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, frames=5):\n",
    "    data = Batch.from_data_list(data_batch[:frames])\n",
    "    data.pos.requires_grad = True\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b99ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 20\n",
    "data = prepare_batch(data_batch, frames=frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8c91d",
   "metadata": {},
   "source": [
    "# Precalculate things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68fb057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "h = model(data[0])\n",
    "d = h.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b4b9c",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656ff5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "def f(pos, data, model):\n",
    "    pos_list = []\n",
    "    batch_idx = data.batch\n",
    "    batch_unique_idx = torch.unique(batch_idx)\n",
    "    for uidx in batch_unique_idx:\n",
    "        pos_list.append(pos[batch_idx == uidx])\n",
    "\n",
    "    data_list = data.to_data_list()\n",
    "    for i, pos in enumerate(pos_list):\n",
    "        data_list[i].pos = pos\n",
    "\n",
    "    new_batch = Batch.from_data_list(data_list)\n",
    "    h = model(new_batch)\n",
    "    return h\n",
    "\n",
    "def prepare_batch_for_f(batch, frames=None):\n",
    "    batch = copy.deepcopy(batch)\n",
    "    if frames is not None:\n",
    "        batch = prepare_batch(batch, frames)\n",
    "    batch.pos.requires_grad = True\n",
    "    pos = batch.pop(\"pos\")\n",
    "    return batch, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3d239",
   "metadata": {},
   "source": [
    "## Try autograd interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cc17ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  -6.2902,    5.1938,   13.4935],\n",
       "        [  24.6666,  -12.7259,  -24.2249],\n",
       "        [  -3.8296,   -5.3556,   -7.1037],\n",
       "        ...,\n",
       "        [  12.9996,    2.3244,   14.8525],\n",
       "        [  29.7450, -108.7377,  244.1773],\n",
       "        [ -12.3267,   60.5505,  -66.2716]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_pos_data, pos = prepare_batch_for_f(data_batch, frames=10)\n",
    "y = f(\n",
    "    pos,\n",
    "    no_pos_data,\n",
    "    model,\n",
    ")\n",
    "m = y.shape[0]\n",
    "gr = torch.autograd.grad(\n",
    "    outputs=y,\n",
    "    inputs=pos,\n",
    "    grad_outputs=torch.ones_like(y),\n",
    "    retain_graph=False,\n",
    "    create_graph=False,\n",
    "    allow_unused=False,\n",
    "    is_grads_batched=False,\n",
    ")[0]\n",
    "gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7072459",
   "metadata": {},
   "source": [
    "## torch.func interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7976194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jvp, vjp, grad, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afd0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function\n",
    "func = torch.func.functionalize(lambda x: f(x, data, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8611fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [940] at index 0 does not match the shape of the indexed tensor [235, 3] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m non_pos_data, pos \u001b[38;5;241m=\u001b[39m prepare_batch_for_f(data_batch, frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m f(\n\u001b[1;32m      4\u001b[0m     pos,\n\u001b[1;32m      5\u001b[0m     non_pos_data,\n\u001b[1;32m      6\u001b[0m     model,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m output, vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m vjp_fn(torch\u001b[38;5;241m.\u001b[39mones_like(torch\u001b[38;5;241m.\u001b[39mones_like(y)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:264\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(func, has_aux, *primals)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;129m@exposed_in\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.func\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(func: Callable, \u001b[38;5;241m*\u001b[39mprimals, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    Standing for the vector-Jacobian product, returns a tuple containing the\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    results of ``func`` applied to ``primals`` and a function that, when\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m        should not depend on the result of a context manager outside of ``f``.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:291\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    289\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 291\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1600\u001b[0m, in \u001b[0;36mfunctionalize.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m flattened_unwrapped_kwargs, _ \u001b[38;5;241m=\u001b[39m tree_flatten(kwargs)\n\u001b[1;32m   1598\u001b[0m flattened_wrapped_kwargs, _ \u001b[38;5;241m=\u001b[39m tree_flatten(func_kwargs)\n\u001b[0;32m-> 1600\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1601\u001b[0m outputs \u001b[38;5;241m=\u001b[39m _unwrap_all_tensors_from_functional(func_outputs, reapply_views\u001b[38;5;241m=\u001b[39mreapply_views)\n\u001b[1;32m   1602\u001b[0m flat_outputs, func_out_spec \u001b[38;5;241m=\u001b[39m tree_flatten(outputs)\n",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m func \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mfunctionalize(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mf\u001b[0;34m(pos, data, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m batch_unique_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munique(batch_idx)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uidx \u001b[38;5;129;01min\u001b[39;00m batch_unique_idx:\n\u001b[0;32m----> 8\u001b[0m     pos_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muidx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     10\u001b[0m data_list \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_data_list()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pos_list):\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [940] at index 0 does not match the shape of the indexed tensor [235, 3] at index 0"
     ]
    }
   ],
   "source": [
    "# First vjp\n",
    "non_pos_data, pos = prepare_batch_for_f(data_batch, frames=5)\n",
    "y = f(\n",
    "    pos,\n",
    "    non_pos_data,\n",
    "    model,\n",
    ")\n",
    "output, vjp_fn = vjp(func, pos)\n",
    "vjp_fn(torch.ones_like(torch.ones_like(y)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pos_data, pos = prepare_batch_for_f(data_batch, frames=5)\n",
    "out, jvp_out = jvp(func, (pos,), (torch.randn(*pos.shape),), strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca58a44",
   "metadata": {},
   "source": [
    "# Gradient KRR\n",
    "\n",
    "Now we focus on using the kernel KRR with gradients, so we need to change the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37add952",
   "metadata": {},
   "outputs": [],
   "source": [
    "gk = GaussianKernel()\n",
    "gk.sigma = 1.0\n",
    "gklme = LinearMeanEmbeddingKernel(gk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9c6e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pre_batch_pos_for_f(pos, no_pos_data):\n",
    "    pos_list = []\n",
    "    batch_idx = no_pos_data.batch\n",
    "    batch_unique_idx = torch.unique(batch_idx)\n",
    "    for uidx in batch_unique_idx:\n",
    "        pos_list.append(pos[batch_idx == uidx])\n",
    "\n",
    "    data_list = no_pos_data.to_data_list()\n",
    "    for i, pos in enumerate(pos_list):\n",
    "        data_list[i].pos = pos\n",
    "\n",
    "    new_batch = Batch.from_data_list(data_list)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ab42f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 20\n",
    "data = prepare_batch(data_batch, frames)\n",
    "no_pos_data, pos = prepare_batch_for_f(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11e5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Operator: Solving the linear system to get the two coefficients\n",
    "\n",
    "# Initial coefficients\n",
    "c0 = torch.randn(frames)\n",
    "c1 = torch.randn(frames, num_atoms, 3)\n",
    "\n",
    "# Will be passed into the model\n",
    "f_kernel_kwargs = {\n",
    "    \"pos\": pos,\n",
    "    \"data\": no_pos_data,\n",
    "    \"kernel\": gklme, \n",
    "    \"model\": model,\n",
    "}\n",
    "\n",
    "# Updates, these are split up into 4 updates 00, 01, 10, 11 for each of the submatrices\n",
    "# We want to express them using autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582f41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "# linop00\n",
    "def f00(pos, data, kernel, model, num_atoms=num_atoms, d=d):\n",
    "    frames = len(torch.unique(data.batch))\n",
    "    new_batch = _pre_batch_pos_for_f(pos, data)\n",
    "    h = model(new_batch).reshape(frames, num_atoms, d)\n",
    "    h_ = h.clone().detach() # Stop gradients\n",
    "    k = kernel(h, h_)\n",
    "    return k\n",
    "\n",
    "def linop00(c0, **f_kernel_kwargs):\n",
    "    \"\"\"f_kernel_kwargs are additional kwargs we pass onto f\"\"\"\n",
    "    with torch.no_grad():\n",
    "        k = f00(**f_kernel_kwargs)\n",
    "    return torch.matmul(k, c0)    \n",
    "\n",
    "c00 = linop00(c0, **f_kernel_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08752938",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     c01 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(jvp_out, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[0;32m---> 26\u001b[0m c01 \u001b[38;5;241m=\u001b[39m \u001b[43mlinop01\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mf_kernel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m, in \u001b[0;36mlinop01\u001b[0;34m(c1, **f_kernel_kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinop01\u001b[39m(c1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mf_kernel_kwargs):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"f_kernel_kwargs are additional kwargs we pass onto f\"\"\"\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43mf_kernel_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Create function\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     func \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mfunctionalize(\u001b[38;5;28;01mlambda\u001b[39;00m x: f01(x, c1, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mf_kernel_kwargs))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pos'"
     ]
    }
   ],
   "source": [
    "# linop01\n",
    "\n",
    "def f01(pos, data, kernel, model, num_atoms=num_atoms, d=d):\n",
    "    frames = len(torch.unique(data.batch))\n",
    "    new_batch = _pre_batch_pos_for_f(pos.reshape(frames*num_atoms, -1), data)\n",
    "    h = model(new_batch).reshape(frames, num_atoms, d)\n",
    "    h_ = h.clone().detach() # Stop gradients\n",
    "    k = kernel(h, h_)\n",
    "    return k\n",
    "\n",
    "def linop01(c1, **f_kernel_kwargs):\n",
    "    \"\"\"f_kernel_kwargs are additional kwargs we pass onto f\"\"\"\n",
    "    pos = f_kernel_kwargs.pop(\"pos\")\n",
    "    # Create function\n",
    "    func = torch.func.functionalize(lambda x: f01(x, c1, **f_kernel_kwargs))\n",
    "    frames = len(torch.unique(data.batch))\n",
    "    print(func(pos.reshape(frames, num_atoms, -1)))\n",
    "    # Get JVP\n",
    "    out, jvp_out = jvp(func, (pos.reshape(frames, num_atoms, -1),), (c1,), strict=True)\n",
    "    # NOTE: this is done so that we have G_t c1 on each row,\n",
    "    # since the linop01 is \\sum_t^T G_t c1 we can make this by simpy summing over the correct axis\n",
    "    # Note that we have nans, I do not know why, but for now we just set it to zero\n",
    "    c01 = torch.nan_to_num(jvp_out, 0.0)\n",
    "    return jvp_out\n",
    "\n",
    "c01 = linop01(c1, **f_kernel_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos, no_pos_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c667d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "f_kernel_kwargs = {\n",
    "    \"pos\": pos,\n",
    "    \"data\": no_pos_data,\n",
    "    \"kernel\": gklme, \n",
    "    \"model\": model,\n",
    "}\n",
    "pos = f_kernel_kwargs.pop(\"pos\")\n",
    "\n",
    "## Test\n",
    "full_h = model(data)\n",
    "full_h = full_h.reshape(frames, num_atoms, -1).clone().detach()\n",
    "\n",
    "def f(pos, data, kernel, model, num_atoms=num_atoms, d=d):\n",
    "    frames = len(torch.unique(data.batch))\n",
    "    new_batch = _pre_batch_pos_for_f(pos, data)\n",
    "    h = model(new_batch).reshape(frames, num_atoms, d)\n",
    "    k = kernel(h, full_h) # 1 x T\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83b5c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n",
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n",
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n",
      "WARNING:root:Turning otf_graph=True as required attributes not present in data object\n"
     ]
    }
   ],
   "source": [
    "dat = Batch.from_data_list([data_batch[0]])\n",
    "pos = dat.pop(\"pos\")\n",
    "f_kernel_kwargs = {\n",
    "    #\"pos\": pos,\n",
    "    \"data\": dat,\n",
    "    \"kernel\": gklme,\n",
    "    \"model\": model,\n",
    "}\n",
    "\n",
    "\n",
    "# Create function\n",
    "# func = torch.func.functionalize(lambda x: f(x, **f_kernel_kwargs))\n",
    "# out, jvp_out = jvp(func, (pos,), (c1.reshape(frames, num_atoms, -1)[0],), strict=True)\n",
    "new_c1s = []\n",
    "for t in range(4):\n",
    "    func = torch.func.functionalize(lambda x: f(x, **f_kernel_kwargs))\n",
    "    out, jvp_out = jvp(func, (pos,), (c1.reshape(frames, num_atoms, -1)[t],), strict=True)\n",
    "    jvp_out = torch.nan_to_num(jvp_out)\n",
    "    new_c1s.append(jvp_out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3070322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000e+00, -1.6500e-02, -3.7023e-02, -7.3338e-03, -2.8508e-03,\n",
       "          -2.4859e-03, -3.6808e-03, -4.6446e-03, -1.5159e-03,  5.4215e-04,\n",
       "           3.0420e-04,  8.6274e-05,  9.2874e-04,  4.0223e-04,  9.4349e-04,\n",
       "           1.8706e-03,  1.8683e-03,  1.1277e-03,  2.4083e-04,  9.9377e-04]],\n",
       "        grad_fn=<NanToNumBackward0>),\n",
       " tensor([[ 0.0000,  0.0557, -0.0100, -0.0024,  0.0004,  0.0025,  0.0032,  0.0024,\n",
       "          -0.0003, -0.0004, -0.0002, -0.0003, -0.0007, -0.0005, -0.0003,  0.0004,\n",
       "           0.0006,  0.0005,  0.0005, -0.0005]], grad_fn=<NanToNumBackward0>),\n",
       " tensor([[ 0.0000,  0.0181,  0.0077, -0.0016, -0.0036, -0.0039, -0.0056, -0.0050,\n",
       "          -0.0012,  0.0008,  0.0005,  0.0005,  0.0005,  0.0009,  0.0012,  0.0018,\n",
       "           0.0020,  0.0011,  0.0002, -0.0004]], grad_fn=<NanToNumBackward0>),\n",
       " tensor([[ 0.0000, -0.0160, -0.0117, -0.0006, -0.0018, -0.0007, -0.0011, -0.0009,\n",
       "          -0.0017, -0.0013, -0.0006, -0.0004,  0.0002, -0.0004, -0.0005, -0.0007,\n",
       "          -0.0007, -0.0002,  0.0002,  0.0007]], grad_fn=<NanToNumBackward0>)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_c1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_h = model(data)\n",
    "full_h = full_h.reshape(frames, num_atoms, -1).clone().detach()\n",
    "\n",
    "def f(pos, data, kernel, model, num_atoms=num_atoms, d=d):\n",
    "    frames = len(torch.unique(data.batch))\n",
    "    assert(frames == 1)\n",
    "    new_batch = _pre_batch_pos_for_f(pos, data)\n",
    "    h = model(new_batch).reshape(frames, num_atoms, d)\n",
    "    k = kernel(h, full_h)\n",
    "    return k\n",
    "\n",
    "\n",
    "\n",
    "# Create function\n",
    "# func = torch.func.functionalize(lambda x: f(x, **f_kernel_kwargs))\n",
    "# out, jvp_out = jvp(func, (pos,), (c1.reshape(frames, num_atoms, -1)[0],), strict=True)\n",
    "jvps = []\n",
    "for t in range(frames):\n",
    "    dat = Batch.from_data_list([data_batch[t]])\n",
    "    pos = dat.pop(\"pos\")\n",
    "    f_kernel_kwargs = {\n",
    "        #\"pos\": pos,\n",
    "        \"data\": dat,\n",
    "        \"kernel\": gklme,\n",
    "        \"model\": model,\n",
    "    }\n",
    "    \n",
    "    func = torch.func.functionalize(lambda x: f(x, **f_kernel_kwargs))\n",
    "    out, jvp_out = jvp(func, (pos,), (c1.reshape(frames, num_atoms, -1)[t],), strict=True)\n",
    "    jvps.append(torch.nan_to_num(jvp_out))\n",
    "jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(jvps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e399491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linop01(c1, **f_kernel_kwargs):\n",
    "    \"\"\"f_kernel_kwargs are additional kwargs we pass onto f\"\"\"\n",
    "    pos = f_kernel_kwargs.pop(\"pos\")\n",
    "    # Create function\n",
    "    func = torch.func.functionalize(lambda x: f01(x, **f_kernel_kwargs))\n",
    "    # Get JVP\n",
    "    out, jvp_out = jvp(func, (pos,), (c1,), strict=True)\n",
    "    # Note, this is done so that we have G_t c1 on each row,\n",
    "    # since the linop01 is \\sum_t^T G_t c1 we can make this by simpy summing over the correct axis\n",
    "    # Note that we have nans, I do not know why, but for now we just set it to zero\n",
    "    c01 = jvp_out.fillna(0.0)\n",
    "    return c0\n",
    "\n",
    "\n",
    "c01 = linop01(c1, **f_kernel_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "c01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a86b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
