{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fafe0ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import warnings\n",
    "from math import pi as PI\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, Linear, ModuleList, Sequential\n",
    "\n",
    "from torch_geometric.data import Dataset, download_url, extract_zip\n",
    "from torch_geometric.data.makedirs import makedirs\n",
    "from torch_geometric.nn import MessagePassing, SumAggregation, radius_graph\n",
    "from torch_geometric.nn.resolver import aggregation_resolver as aggr_resolver\n",
    "from torch_geometric.typing import OptTensor\n",
    "\n",
    "qm9_target_dict: Dict[int, str] = {\n",
    "    0: 'dipole_moment',\n",
    "    1: 'isotropic_polarizability',\n",
    "    2: 'homo',\n",
    "    3: 'lumo',\n",
    "    4: 'gap',\n",
    "    5: 'electronic_spatial_extent',\n",
    "    6: 'zpve',\n",
    "    7: 'energy_U0',\n",
    "    8: 'energy_U',\n",
    "    9: 'enthalpy_H',\n",
    "    10: 'free_energy',\n",
    "    11: 'heat_capacity',\n",
    "}\n",
    "\n",
    "\n",
    "class SchNet(torch.nn.Module):\n",
    "    r\"\"\"The continuous-filter convolutional neural network SchNet from the\n",
    "    `\"SchNet: A Continuous-filter Convolutional Neural Network for Modeling\n",
    "    Quantum Interactions\" <https://arxiv.org/abs/1706.08566>`_ paper that uses\n",
    "    the interactions blocks of the form\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{x}_j \\odot\n",
    "        h_{\\mathbf{\\Theta}} ( \\exp(-\\gamma(\\mathbf{e}_{j,i} - \\mathbf{\\mu}))),\n",
    "\n",
    "    here :math:`h_{\\mathbf{\\Theta}}` denotes an MLP and\n",
    "    :math:`\\mathbf{e}_{j,i}` denotes the interatomic distances between atoms.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using a pretrained SchNet variant, see\n",
    "        `examples/qm9_pretrained_schnet.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        qm9_pretrained_schnet.py>`_.\n",
    "\n",
    "    Args:\n",
    "        hidden_channels (int, optional): Hidden embedding size.\n",
    "            (default: :obj:`128`)\n",
    "        num_filters (int, optional): The number of filters to use.\n",
    "            (default: :obj:`128`)\n",
    "        num_interactions (int, optional): The number of interaction blocks.\n",
    "            (default: :obj:`6`)\n",
    "        num_gaussians (int, optional): The number of gaussians :math:`\\mu`.\n",
    "            (default: :obj:`50`)\n",
    "        interaction_graph (callable, optional): The function used to compute\n",
    "            the pairwise interaction graph and interatomic distances. If set to\n",
    "            :obj:`None`, will construct a graph based on :obj:`cutoff` and\n",
    "            :obj:`max_num_neighbors` properties.\n",
    "            If provided, this method takes in :obj:`pos` and :obj:`batch`\n",
    "            tensors and should return :obj:`(edge_index, edge_weight)` tensors.\n",
    "            (default :obj:`None`)\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
    "            collect for each node within the :attr:`cutoff` distance.\n",
    "            (default: :obj:`32`)\n",
    "        readout (str, optional): Whether to apply :obj:`\"add\"` or :obj:`\"mean\"`\n",
    "            global aggregation. (default: :obj:`\"add\"`)\n",
    "        dipole (bool, optional): If set to :obj:`True`, will use the magnitude\n",
    "            of the dipole moment to make the final prediction, *e.g.*, for\n",
    "            target 0 of :class:`torch_geometric.datasets.QM9`.\n",
    "            (default: :obj:`False`)\n",
    "        mean (float, optional): The mean of the property to predict.\n",
    "            (default: :obj:`None`)\n",
    "        std (float, optional): The standard deviation of the property to\n",
    "            predict. (default: :obj:`None`)\n",
    "        atomref (torch.Tensor, optional): The reference of single-atom\n",
    "            properties.\n",
    "            Expects a vector of shape :obj:`(max_atomic_number, )`.\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'http://www.quantum-machine.org/datasets/trained_schnet_models.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 128,\n",
    "        num_filters: int = 128,\n",
    "        num_interactions: int = 6,\n",
    "        representation_layer: int = 2,\n",
    "        num_gaussians: int = 50,\n",
    "        cutoff: float = 10.0,\n",
    "        interaction_graph: Optional[Callable] = None,\n",
    "        max_num_neighbors: int = 32,\n",
    "        readout: str = 'add',\n",
    "        dipole: bool = False,\n",
    "        mean: Optional[float] = None,\n",
    "        std: Optional[float] = None,\n",
    "        atomref: OptTensor = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_filters = num_filters\n",
    "        self.num_interactions = num_interactions\n",
    "        self.representation_layer = representation_layer\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.cutoff = cutoff\n",
    "        self.dipole = dipole\n",
    "        self.sum_aggr = SumAggregation()\n",
    "        self.readout = aggr_resolver('sum' if self.dipole else readout)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.scale = None\n",
    "\n",
    "        if self.dipole:\n",
    "            import ase\n",
    "\n",
    "            atomic_mass = torch.from_numpy(ase.data.atomic_masses)\n",
    "            self.register_buffer('atomic_mass', atomic_mass)\n",
    "\n",
    "        # Support z == 0 for padding atoms so that their embedding vectors\n",
    "        # are zeroed and do not receive any gradients.\n",
    "        self.embedding = Embedding(100, hidden_channels, padding_idx=0)\n",
    "\n",
    "        if interaction_graph is not None:\n",
    "            self.interaction_graph = interaction_graph\n",
    "        else:\n",
    "            self.interaction_graph = RadiusInteractionGraph(\n",
    "                cutoff, max_num_neighbors)\n",
    "\n",
    "        self.distance_expansion = GaussianSmearing(0.0, cutoff, num_gaussians)\n",
    "\n",
    "        self.interactions = ModuleList()\n",
    "        for _ in range(num_interactions):\n",
    "            block = InteractionBlock(hidden_channels, num_gaussians,\n",
    "                                     num_filters, cutoff)\n",
    "            self.interactions.append(block)\n",
    "\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels // 2)\n",
    "        self.act = ShiftedSoftplus()\n",
    "        self.lin2 = Linear(hidden_channels // 2, 1)\n",
    "\n",
    "        self.register_buffer('initial_atomref', atomref)\n",
    "        self.atomref = None\n",
    "        if atomref is not None:\n",
    "            self.atomref = Embedding(100, 1)\n",
    "            self.atomref.weight.data.copy_(atomref)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        self.embedding.reset_parameters()\n",
    "        for interaction in self.interactions:\n",
    "            interaction.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        self.lin1.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "        if self.atomref is not None:\n",
    "            self.atomref.weight.data.copy_(self.initial_atomref)\n",
    "\n",
    "    def forward(self, z: Tensor, pos: Tensor,\n",
    "                batch: OptTensor = None) -> Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            z (torch.Tensor): Atomic number of each atom with shape\n",
    "                :obj:`[num_atoms]`.\n",
    "            pos (torch.Tensor): Coordinates of each atom with shape\n",
    "                :obj:`[num_atoms, 3]`.\n",
    "            batch (torch.Tensor, optional): Batch indices assigning each atom\n",
    "                to a separate molecule with shape :obj:`[num_atoms]`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        batch = torch.zeros_like(z) if batch is None else batch\n",
    "\n",
    "        h = self.embedding(z)\n",
    "        edge_index, edge_weight = self.interaction_graph(pos, batch)\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        for i, interaction in enumerate(self.interactions):\n",
    "            h = h + interaction(h, edge_index, edge_weight, edge_attr)\n",
    "            if i == self.representation_layer:\n",
    "                return h\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = self.act(h)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        if self.dipole:\n",
    "            # Get center of mass.\n",
    "            mass = self.atomic_mass[z].view(-1, 1)\n",
    "            M = self.sum_aggr(mass, batch, dim=0)\n",
    "            c = self.sum_aggr(mass * pos, batch, dim=0) / M\n",
    "            h = h * (pos - c.index_select(0, batch))\n",
    "\n",
    "        if not self.dipole and self.mean is not None and self.std is not None:\n",
    "            h = h * self.std + self.mean\n",
    "\n",
    "        if not self.dipole and self.atomref is not None:\n",
    "            h = h + self.atomref(z)\n",
    "\n",
    "        out = self.readout(h, batch, dim=0)\n",
    "\n",
    "        if self.dipole:\n",
    "            out = torch.norm(out, dim=-1, keepdim=True)\n",
    "\n",
    "        if self.scale is not None:\n",
    "            out = self.scale * out\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}('\n",
    "                f'hidden_channels={self.hidden_channels}, '\n",
    "                f'num_filters={self.num_filters}, '\n",
    "                f'num_interactions={self.num_interactions}, '\n",
    "                f'num_gaussians={self.num_gaussians}, '\n",
    "                f'cutoff={self.cutoff})')\n",
    "\n",
    "\n",
    "\n",
    "class RadiusInteractionGraph(torch.nn.Module):\n",
    "    r\"\"\"Creates edges based on atom positions :obj:`pos` to all points within\n",
    "    the cutoff distance.\n",
    "\n",
    "    Args:\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
    "            collect for each node within the :attr:`cutoff` distance with the\n",
    "            default interaction graph method.\n",
    "            (default: :obj:`32`)\n",
    "    \"\"\"\n",
    "    def __init__(self, cutoff: float = 10.0, max_num_neighbors: int = 32):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.max_num_neighbors = max_num_neighbors\n",
    "\n",
    "    def forward(self, pos: Tensor, batch: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            pos (Tensor): Coordinates of each atom.\n",
    "            batch (LongTensor, optional): Batch indices assigning each atom to\n",
    "                a separate molecule.\n",
    "\n",
    "        :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
    "                                  max_num_neighbors=self.max_num_neighbors)\n",
    "        row, col = edge_index\n",
    "        edge_weight = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "class InteractionBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels: int, num_gaussians: int,\n",
    "                 num_filters: int, cutoff: float):\n",
    "        super().__init__()\n",
    "        self.mlp = Sequential(\n",
    "            Linear(num_gaussians, num_filters),\n",
    "            ShiftedSoftplus(),\n",
    "            Linear(num_filters, num_filters),\n",
    "        )\n",
    "        self.conv = CFConv(hidden_channels, hidden_channels, num_filters,\n",
    "                           self.mlp, cutoff)\n",
    "        self.act = ShiftedSoftplus()\n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[0].weight)\n",
    "        self.mlp[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[2].weight)\n",
    "        self.mlp[2].bias.data.fill_(0)\n",
    "        self.conv.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.lin.weight)\n",
    "        self.lin.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor,\n",
    "                edge_attr: Tensor) -> Tensor:\n",
    "        x = self.conv(x, edge_index, edge_weight, edge_attr)\n",
    "        x = self.act(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CFConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        num_filters: int,\n",
    "        nn: Sequential,\n",
    "        cutoff: float,\n",
    "    ):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin1 = Linear(in_channels, num_filters, bias=False)\n",
    "        self.lin2 = Linear(num_filters, out_channels)\n",
    "        self.nn = nn\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor,\n",
    "                edge_attr: Tensor) -> Tensor:\n",
    "        C = 0.5 * (torch.cos(edge_weight * PI / self.cutoff) + 1.0)\n",
    "        W = self.nn(edge_attr) * C.view(-1, 1)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.propagate(edge_index, x=x, W=W)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j: Tensor, W: Tensor) -> Tensor:\n",
    "        return x_j * W\n",
    "\n",
    "\n",
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start: float = 0.0,\n",
    "        stop: float = 5.0,\n",
    "        num_gaussians: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist: Tensor) -> Tensor:\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))\n",
    "\n",
    "\n",
    "class ShiftedSoftplus(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softplus(x) - self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b506f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch, Data\n",
    "import functorch\n",
    "import copy\n",
    "from ocpmodels.transfer_learning.models.distribution_regression import (\n",
    "    GaussianKernel,\n",
    "    KernelMeanEmbeddingRidgeRegression,\n",
    "    LinearMeanEmbeddingKernel,\n",
    "    StandardizedOutputRegression,\n",
    "    median_heuristic,\n",
    ")\n",
    "\n",
    "from ocpmodels.transfer_learning.common.utils import (\n",
    "    ATOMS_TO_GRAPH_KWARGS,\n",
    "    load_xyz_to_pyg_batch,\n",
    "    load_xyz_to_pyg_data,\n",
    ")\n",
    "from ocpmodels.transfer_learning.loaders import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcb354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/isak/life/references/projects/src/python_lang/ocp\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b79b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isak/life/references/projects/src/python_lang/ocp/ocpmodels/preprocessing/atoms_to_graphs.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  cell = torch.Tensor(atoms.get_cell()).view(1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "### Load checkpoint\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/s2ef_efwt/all/schnet/schnet_all_large.pt\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "\n",
    "### Load data\n",
    "DATA_PATH = Path(\"data/luigi/example-traj-Fe-N2-111.xyz\")\n",
    "raw_data, data_batch, num_frames, num_atoms = load_xyz_to_pyg_batch(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "raw_data, data_list, num_frames, num_atoms = load_xyz_to_pyg_data(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6a27428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a schnet from torch_geometric\n",
    "#from torch_geometric.nn import SchNet\n",
    "\n",
    "schnet = SchNet(\n",
    "        hidden_channels = 9,\n",
    "        num_filters =  4,\n",
    "        num_interactions = 2,\n",
    "        representation_layer = 1,\n",
    "        num_gaussians = 4,\n",
    "        cutoff = 6.0,\n",
    "        max_num_neighbors = 32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54116c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_ = 3\n",
    "data_batch_ = Batch.from_data_list(data_batch[:num_frames_])\n",
    "data_batch_.pos.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "091be1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = schnet(\n",
    "    data_batch_.atomic_numbers.long(), \n",
    "    data_batch_.pos,\n",
    "    data_batch_.batch\n",
    ")\n",
    "h_me = h.reshape(num_frames_, num_atoms, -1).mean(1)\n",
    "k = h_me @ h_me.T\n",
    "\n",
    "def f(pos, z, batch):\n",
    "    h = schnet(\n",
    "        z.long(), \n",
    "        pos,\n",
    "        batch\n",
    "    )\n",
    "    h_me = h.reshape(num_frames_, num_atoms, -1).mean(1)\n",
    "    k = h_me @ h_me.T\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8ad09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import vmap, grad, vjp, jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d76d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = grad(lambda x: f(x, data_batch_.atomic_numbers.long(), data_batch_.batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26e7125b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/isak/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch_cluster/radius.py\", line 118, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/isak/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch_cluster/radius.py\", line 72, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1380\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1380\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1382\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/vmap.py:39\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/_functorch/eager_transforms.py:1245\u001b[0m, in \u001b[0;36mgrad_and_value.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m diff_args \u001b[38;5;241m=\u001b[39m _slice_argnums(args, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1243\u001b[0m tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_args)\n\u001b[0;32m-> 1245\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[38;5;241m=\u001b[39m grad(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic_numbers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_batch_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[60], line 10\u001b[0m, in \u001b[0;36mf\u001b[0;34m(pos, z, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(pos, z, batch):\n\u001b[0;32m---> 10\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mschnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     h_me \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mreshape(num_frames_, num_atoms, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     k \u001b[38;5;241m=\u001b[39m h_me \u001b[38;5;241m@\u001b[39m h_me\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[27], line 187\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, z, pos, batch)\u001b[0m\n\u001b[1;32m    184\u001b[0m batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(z) \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m batch\n\u001b[1;32m    186\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(z)\n\u001b[0;32m--> 187\u001b[0m edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteraction_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistance_expansion(edge_weight)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, interaction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteractions):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[27], line 259\u001b[0m, in \u001b[0;36mRadiusInteractionGraph.forward\u001b[0;34m(self, pos, batch)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pos: Tensor, batch: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m        pos (Tensor): Coordinates of each atom.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    :rtype: (:class:`LongTensor`, :class:`Tensor`)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mradius_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmax_num_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_num_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m edge_index\n\u001b[1;32m    262\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m (pos[row] \u001b[38;5;241m-\u001b[39m pos[col])\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py:210\u001b[0m, in \u001b[0;36mradius_graph\u001b[0;34m(x, r, batch, loop, max_num_neighbors, flow, num_workers)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradius_graph\u001b[39m(x: Tensor, r: \u001b[38;5;28mfloat\u001b[39m, batch: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m                  loop: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, max_num_neighbors: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    177\u001b[0m                  flow: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    178\u001b[0m                  num_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes graph edges to all points within a given distance.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    .. code-block:: python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    :rtype: :class:`torch.Tensor`\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/isak/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch_cluster/radius.py\", line 118, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/isak/.local/share/virtualenvs/ocp-7tiAki73/lib/python3.9/site-packages/torch_cluster/radius.py\", line 72, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n"
     ]
    }
   ],
   "source": [
    "g(data_batch_.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6a58a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
