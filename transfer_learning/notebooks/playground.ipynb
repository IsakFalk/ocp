{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fafe0ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import warnings\n",
    "from math import pi as PI\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, Linear, ModuleList, Sequential\n",
    "\n",
    "from torch_geometric.data import Dataset, download_url, extract_zip\n",
    "from torch_geometric.data.makedirs import makedirs\n",
    "from torch_geometric.nn import MessagePassing, SumAggregation, radius_graph\n",
    "from torch_geometric.nn.resolver import aggregation_resolver as aggr_resolver\n",
    "from torch_geometric.typing import OptTensor\n",
    "\n",
    "qm9_target_dict: Dict[int, str] = {\n",
    "    0: 'dipole_moment',\n",
    "    1: 'isotropic_polarizability',\n",
    "    2: 'homo',\n",
    "    3: 'lumo',\n",
    "    4: 'gap',\n",
    "    5: 'electronic_spatial_extent',\n",
    "    6: 'zpve',\n",
    "    7: 'energy_U0',\n",
    "    8: 'energy_U',\n",
    "    9: 'enthalpy_H',\n",
    "    10: 'free_energy',\n",
    "    11: 'heat_capacity',\n",
    "}\n",
    "\n",
    "\n",
    "class SchNet(torch.nn.Module):\n",
    "    r\"\"\"The continuous-filter convolutional neural network SchNet from the\n",
    "    `\"SchNet: A Continuous-filter Convolutional Neural Network for Modeling\n",
    "    Quantum Interactions\" <https://arxiv.org/abs/1706.08566>`_ paper that uses\n",
    "    the interactions blocks of the form\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{x}_j \\odot\n",
    "        h_{\\mathbf{\\Theta}} ( \\exp(-\\gamma(\\mathbf{e}_{j,i} - \\mathbf{\\mu}))),\n",
    "\n",
    "    here :math:`h_{\\mathbf{\\Theta}}` denotes an MLP and\n",
    "    :math:`\\mathbf{e}_{j,i}` denotes the interatomic distances between atoms.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using a pretrained SchNet variant, see\n",
    "        `examples/qm9_pretrained_schnet.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        qm9_pretrained_schnet.py>`_.\n",
    "\n",
    "    Args:\n",
    "        hidden_channels (int, optional): Hidden embedding size.\n",
    "            (default: :obj:`128`)\n",
    "        num_filters (int, optional): The number of filters to use.\n",
    "            (default: :obj:`128`)\n",
    "        num_interactions (int, optional): The number of interaction blocks.\n",
    "            (default: :obj:`6`)\n",
    "        num_gaussians (int, optional): The number of gaussians :math:`\\mu`.\n",
    "            (default: :obj:`50`)\n",
    "        interaction_graph (callable, optional): The function used to compute\n",
    "            the pairwise interaction graph and interatomic distances. If set to\n",
    "            :obj:`None`, will construct a graph based on :obj:`cutoff` and\n",
    "            :obj:`max_num_neighbors` properties.\n",
    "            If provided, this method takes in :obj:`pos` and :obj:`batch`\n",
    "            tensors and should return :obj:`(edge_index, edge_weight)` tensors.\n",
    "            (default :obj:`None`)\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
    "            collect for each node within the :attr:`cutoff` distance.\n",
    "            (default: :obj:`32`)\n",
    "        readout (str, optional): Whether to apply :obj:`\"add\"` or :obj:`\"mean\"`\n",
    "            global aggregation. (default: :obj:`\"add\"`)\n",
    "        dipole (bool, optional): If set to :obj:`True`, will use the magnitude\n",
    "            of the dipole moment to make the final prediction, *e.g.*, for\n",
    "            target 0 of :class:`torch_geometric.datasets.QM9`.\n",
    "            (default: :obj:`False`)\n",
    "        mean (float, optional): The mean of the property to predict.\n",
    "            (default: :obj:`None`)\n",
    "        std (float, optional): The standard deviation of the property to\n",
    "            predict. (default: :obj:`None`)\n",
    "        atomref (torch.Tensor, optional): The reference of single-atom\n",
    "            properties.\n",
    "            Expects a vector of shape :obj:`(max_atomic_number, )`.\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'http://www.quantum-machine.org/datasets/trained_schnet_models.zip'\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_channels: int = 128,\n",
    "        num_filters: int = 128,\n",
    "        num_interactions: int = 6,\n",
    "        representation_layer: int = 2,\n",
    "        num_gaussians: int = 50,\n",
    "        cutoff: float = 10.0,\n",
    "        interaction_graph: Optional[Callable] = None,\n",
    "        max_num_neighbors: int = 32,\n",
    "        readout: str = 'add',\n",
    "        dipole: bool = False,\n",
    "        mean: Optional[float] = None,\n",
    "        std: Optional[float] = None,\n",
    "        atomref: OptTensor = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_filters = num_filters\n",
    "        self.num_interactions = num_interactions\n",
    "        self.representation_layer = representation_layer\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.cutoff = cutoff\n",
    "        self.dipole = dipole\n",
    "        self.sum_aggr = SumAggregation()\n",
    "        self.readout = aggr_resolver('sum' if self.dipole else readout)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.scale = None\n",
    "\n",
    "        if self.dipole:\n",
    "            import ase\n",
    "\n",
    "            atomic_mass = torch.from_numpy(ase.data.atomic_masses)\n",
    "            self.register_buffer('atomic_mass', atomic_mass)\n",
    "\n",
    "        # Support z == 0 for padding atoms so that their embedding vectors\n",
    "        # are zeroed and do not receive any gradients.\n",
    "        self.embedding = Embedding(100, hidden_channels, padding_idx=0)\n",
    "\n",
    "        if interaction_graph is not None:\n",
    "            self.interaction_graph = interaction_graph\n",
    "        else:\n",
    "            self.interaction_graph = RadiusInteractionGraph(\n",
    "                cutoff, max_num_neighbors)\n",
    "\n",
    "        self.distance_expansion = GaussianSmearing(0.0, cutoff, num_gaussians)\n",
    "\n",
    "        self.interactions = ModuleList()\n",
    "        for _ in range(num_interactions):\n",
    "            block = InteractionBlock(hidden_channels, num_gaussians,\n",
    "                                     num_filters, cutoff)\n",
    "            self.interactions.append(block)\n",
    "\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels // 2)\n",
    "        self.act = ShiftedSoftplus()\n",
    "        self.lin2 = Linear(hidden_channels // 2, 1)\n",
    "\n",
    "        self.register_buffer('initial_atomref', atomref)\n",
    "        self.atomref = None\n",
    "        if atomref is not None:\n",
    "            self.atomref = Embedding(100, 1)\n",
    "            self.atomref.weight.data.copy_(atomref)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        self.embedding.reset_parameters()\n",
    "        for interaction in self.interactions:\n",
    "            interaction.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        self.lin1.bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "        if self.atomref is not None:\n",
    "            self.atomref.weight.data.copy_(self.initial_atomref)\n",
    "\n",
    "    def forward(self, z: Tensor, pos: Tensor,\n",
    "                batch: OptTensor = None) -> Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            z (torch.Tensor): Atomic number of each atom with shape\n",
    "                :obj:`[num_atoms]`.\n",
    "            pos (torch.Tensor): Coordinates of each atom with shape\n",
    "                :obj:`[num_atoms, 3]`.\n",
    "            batch (torch.Tensor, optional): Batch indices assigning each atom\n",
    "                to a separate molecule with shape :obj:`[num_atoms]`.\n",
    "                (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        batch = torch.zeros_like(z) if batch is None else batch\n",
    "\n",
    "        h = self.embedding(z)\n",
    "        edge_index, edge_weight = self.interaction_graph(pos, batch)\n",
    "        edge_attr = self.distance_expansion(edge_weight)\n",
    "\n",
    "        for i, interaction in enumerate(self.interactions):\n",
    "            h = h + interaction(h, edge_index, edge_weight, edge_attr)\n",
    "            if i == self.representation_layer:\n",
    "                return h\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = self.act(h)\n",
    "        h = self.lin2(h)\n",
    "\n",
    "        if self.dipole:\n",
    "            # Get center of mass.\n",
    "            mass = self.atomic_mass[z].view(-1, 1)\n",
    "            M = self.sum_aggr(mass, batch, dim=0)\n",
    "            c = self.sum_aggr(mass * pos, batch, dim=0) / M\n",
    "            h = h * (pos - c.index_select(0, batch))\n",
    "\n",
    "        if not self.dipole and self.mean is not None and self.std is not None:\n",
    "            h = h * self.std + self.mean\n",
    "\n",
    "        if not self.dipole and self.atomref is not None:\n",
    "            h = h + self.atomref(z)\n",
    "\n",
    "        out = self.readout(h, batch, dim=0)\n",
    "\n",
    "        if self.dipole:\n",
    "            out = torch.norm(out, dim=-1, keepdim=True)\n",
    "\n",
    "        if self.scale is not None:\n",
    "            out = self.scale * out\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}('\n",
    "                f'hidden_channels={self.hidden_channels}, '\n",
    "                f'num_filters={self.num_filters}, '\n",
    "                f'num_interactions={self.num_interactions}, '\n",
    "                f'num_gaussians={self.num_gaussians}, '\n",
    "                f'cutoff={self.cutoff})')\n",
    "\n",
    "\n",
    "\n",
    "class RadiusInteractionGraph(torch.nn.Module):\n",
    "    r\"\"\"Creates edges based on atom positions :obj:`pos` to all points within\n",
    "    the cutoff distance.\n",
    "\n",
    "    Args:\n",
    "        cutoff (float, optional): Cutoff distance for interatomic interactions.\n",
    "            (default: :obj:`10.0`)\n",
    "        max_num_neighbors (int, optional): The maximum number of neighbors to\n",
    "            collect for each node within the :attr:`cutoff` distance with the\n",
    "            default interaction graph method.\n",
    "            (default: :obj:`32`)\n",
    "    \"\"\"\n",
    "    def __init__(self, cutoff: float = 10.0, max_num_neighbors: int = 32):\n",
    "        super().__init__()\n",
    "        self.cutoff = cutoff\n",
    "        self.max_num_neighbors = max_num_neighbors\n",
    "\n",
    "    def forward(self, pos: Tensor, batch: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            pos (Tensor): Coordinates of each atom.\n",
    "            batch (LongTensor, optional): Batch indices assigning each atom to\n",
    "                a separate molecule.\n",
    "\n",
    "        :rtype: (:class:`LongTensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "        edge_index = radius_graph(pos, r=self.cutoff, batch=batch,\n",
    "                                  max_num_neighbors=self.max_num_neighbors)\n",
    "        row, col = edge_index\n",
    "        edge_weight = (pos[row] - pos[col]).norm(dim=-1)\n",
    "        return edge_index, edge_weight\n",
    "\n",
    "\n",
    "class InteractionBlock(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels: int, num_gaussians: int,\n",
    "                 num_filters: int, cutoff: float):\n",
    "        super().__init__()\n",
    "        self.mlp = Sequential(\n",
    "            Linear(num_gaussians, num_filters),\n",
    "            ShiftedSoftplus(),\n",
    "            Linear(num_filters, num_filters),\n",
    "        )\n",
    "        self.conv = CFConv(hidden_channels, hidden_channels, num_filters,\n",
    "                           self.mlp, cutoff)\n",
    "        self.act = ShiftedSoftplus()\n",
    "        self.lin = Linear(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[0].weight)\n",
    "        self.mlp[0].bias.data.fill_(0)\n",
    "        torch.nn.init.xavier_uniform_(self.mlp[2].weight)\n",
    "        self.mlp[2].bias.data.fill_(0)\n",
    "        self.conv.reset_parameters()\n",
    "        torch.nn.init.xavier_uniform_(self.lin.weight)\n",
    "        self.lin.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor,\n",
    "                edge_attr: Tensor) -> Tensor:\n",
    "        x = self.conv(x, edge_index, edge_weight, edge_attr)\n",
    "        x = self.act(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CFConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        num_filters: int,\n",
    "        nn: Sequential,\n",
    "        cutoff: float,\n",
    "    ):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin1 = Linear(in_channels, num_filters, bias=False)\n",
    "        self.lin2 = Linear(num_filters, out_channels)\n",
    "        self.nn = nn\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        self.lin2.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor,\n",
    "                edge_attr: Tensor) -> Tensor:\n",
    "        C = 0.5 * (torch.cos(edge_weight * PI / self.cutoff) + 1.0)\n",
    "        W = self.nn(edge_attr) * C.view(-1, 1)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.propagate(edge_index, x=x, W=W)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_j: Tensor, W: Tensor) -> Tensor:\n",
    "        return x_j * W\n",
    "\n",
    "\n",
    "class GaussianSmearing(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start: float = 0.0,\n",
    "        stop: float = 5.0,\n",
    "        num_gaussians: int = 50,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        offset = torch.linspace(start, stop, num_gaussians)\n",
    "        self.coeff = -0.5 / (offset[1] - offset[0]).item()**2\n",
    "        self.register_buffer('offset', offset)\n",
    "\n",
    "    def forward(self, dist: Tensor) -> Tensor:\n",
    "        dist = dist.view(-1, 1) - self.offset.view(1, -1)\n",
    "        return torch.exp(self.coeff * torch.pow(dist, 2))\n",
    "\n",
    "\n",
    "class ShiftedSoftplus(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shift = torch.log(torch.tensor(2.0)).item()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return F.softplus(x) - self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b506f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Batch, Data\n",
    "import functorch\n",
    "import copy\n",
    "from ocpmodels.transfer_learning.models.distribution_regression import (\n",
    "    GaussianKernel,\n",
    "    KernelMeanEmbeddingRidgeRegression,\n",
    "    LinearMeanEmbeddingKernel,\n",
    "    StandardizedOutputRegression,\n",
    "    median_heuristic,\n",
    ")\n",
    "\n",
    "from ocpmodels.transfer_learning.common.utils import (\n",
    "    ATOMS_TO_GRAPH_KWARGS,\n",
    "    load_xyz_to_pyg_batch,\n",
    "    load_xyz_to_pyg_data,\n",
    ")\n",
    "from ocpmodels.transfer_learning.loaders import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5abb834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/novelli/ocp\n"
     ]
    }
   ],
   "source": [
    "%cd /home/novelli/ocp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b79b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/novelli/ocp/ocpmodels/preprocessing/atoms_to_graphs.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525551200/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  cell = torch.Tensor(atoms.get_cell()).view(1, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "### Load checkpoint\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/s2ef_efwt/all/schnet/schnet_all_large.pt\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\")\n",
    "\n",
    "### Load data\n",
    "DATA_PATH = Path(\"data/luigi/example-traj-Fe-N2-111.xyz\")\n",
    "raw_data, data_batch, num_frames, num_atoms = load_xyz_to_pyg_batch(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "raw_data, data_list, num_frames, num_atoms = load_xyz_to_pyg_data(DATA_PATH, ATOMS_TO_GRAPH_KWARGS[\"schnet\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a27428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a schnet from torch_geometric\n",
    "#from torch_geometric.nn import SchNet\n",
    "\n",
    "schnet = SchNet(\n",
    "        hidden_channels = 9,\n",
    "        num_filters =  4,\n",
    "        num_interactions = 2,\n",
    "        representation_layer = 1,\n",
    "        num_gaussians = 4,\n",
    "        cutoff = 6.0,\n",
    "        max_num_neighbors = 32,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54116c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames_ = 20\n",
    "data_batch_ = Batch.from_data_list(data_batch[:num_frames_]).to(device)\n",
    "data_batch_.pos.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "091be1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = schnet(\n",
    "#     data_batch_.atomic_numbers.long(), \n",
    "#     data_batch_.pos,\n",
    "#     data_batch_.batch\n",
    "# )\n",
    "# h_me = h.reshape(num_frames_, num_atoms, -1).mean(1)\n",
    "# k = h_me @ h_me.T\n",
    "\n",
    "def f(pos, z, batch):\n",
    "    h = schnet(\n",
    "        z.long(), \n",
    "        pos,\n",
    "        batch\n",
    "    )\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8296391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9451,  0.1336, -0.3943,  ...,  1.2686, -2.0303,  0.8143],\n",
       "        [ 2.1118, -0.0271, -0.0460,  ...,  1.1973, -2.1599,  0.7447],\n",
       "        [ 1.9394,  0.1911, -0.3314,  ...,  1.3096, -2.0183,  0.8803],\n",
       "        ...,\n",
       "        [ 2.3122, -0.0707, -0.0203,  ...,  1.2096, -1.9787,  0.5973],\n",
       "        [-2.7936, -0.4506, -0.5943,  ..., -1.0293, -0.7852,  1.3453],\n",
       "        [-2.5112, -0.5131, -0.4173,  ..., -1.0663, -0.7132,  1.2155]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(data_batch_.pos, data_batch_.atomic_numbers.long(), data_batch_.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ad09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import vmap, grad, vjp, jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cbe73b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 116, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 70, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output, jvp_out \u001b[39m=\u001b[39m jvp(\n\u001b[1;32m      2\u001b[0m     func\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: f(x, data_batch_\u001b[39m.\u001b[39;49matomic_numbers\u001b[39m.\u001b[39;49mlong(), data_batch_\u001b[39m.\u001b[39;49mbatch),\n\u001b[1;32m      3\u001b[0m     primals\u001b[39m=\u001b[39;49m(data_batch_\u001b[39m.\u001b[39;49mpos,),\n\u001b[1;32m      4\u001b[0m     tangents\u001b[39m=\u001b[39;49m(torch\u001b[39m.\u001b[39;49mones_like(data_batch_\u001b[39m.\u001b[39;49mpos),),\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:788\u001b[0m, in \u001b[0;36mjvp\u001b[0;34m(func, primals, tangents, strict, has_aux)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjvp\u001b[39m(func: Callable, primals: Any, tangents: Any, \u001b[39m*\u001b[39m, strict: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, has_aux: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    738\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m    Standing for the Jacobian-vector product, returns a tuple containing\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39m    the output of `func(*primals)` and the \"Jacobian of ``func`` evaluated at\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m \n\u001b[1;32m    786\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 788\u001b[0m     \u001b[39mreturn\u001b[39;00m _jvp_with_argnums(func, primals, tangents, argnums\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, strict\u001b[39m=\u001b[39;49mstrict, has_aux\u001b[39m=\u001b[39;49mhas_aux)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/vmap.py:35\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:837\u001b[0m, in \u001b[0;36m_jvp_with_argnums\u001b[0;34m(func, primals, tangents, argnums, strict, has_aux)\u001b[0m\n\u001b[1;32m    835\u001b[0m     primals \u001b[39m=\u001b[39m _wrap_all_tensors(primals, level)\n\u001b[1;32m    836\u001b[0m     duals \u001b[39m=\u001b[39m _replace_args(primals, duals, argnums)\n\u001b[0;32m--> 837\u001b[0m result_duals \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mduals)\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m    839\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(result_duals, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(result_duals) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m output, jvp_out \u001b[39m=\u001b[39m jvp(\n\u001b[0;32m----> 2\u001b[0m     func\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: f(x, data_batch_\u001b[39m.\u001b[39;49matomic_numbers\u001b[39m.\u001b[39;49mlong(), data_batch_\u001b[39m.\u001b[39;49mbatch),\n\u001b[1;32m      3\u001b[0m     primals\u001b[39m=\u001b[39m(data_batch_\u001b[39m.\u001b[39mpos,),\n\u001b[1;32m      4\u001b[0m     tangents\u001b[39m=\u001b[39m(torch\u001b[39m.\u001b[39mones_like(data_batch_\u001b[39m.\u001b[39mpos),),\n\u001b[1;32m      5\u001b[0m )\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mf\u001b[0;34m(pos, z, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(pos, z, batch):\n\u001b[0;32m---> 10\u001b[0m     h \u001b[39m=\u001b[39m schnet(\n\u001b[1;32m     11\u001b[0m         z\u001b[39m.\u001b[39;49mlong(), \n\u001b[1;32m     12\u001b[0m         pos,\n\u001b[1;32m     13\u001b[0m         batch\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 187\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, z, pos, batch)\u001b[0m\n\u001b[1;32m    184\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(z) \u001b[39mif\u001b[39;00m batch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m batch\n\u001b[1;32m    186\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(z)\n\u001b[0;32m--> 187\u001b[0m edge_index, edge_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minteraction_graph(pos, batch)\n\u001b[1;32m    188\u001b[0m edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_expansion(edge_weight)\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m i, interaction \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteractions):\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 259\u001b[0m, in \u001b[0;36mRadiusInteractionGraph.forward\u001b[0;34m(self, pos, batch)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, pos: Tensor, batch: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m        pos (Tensor): Coordinates of each atom.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39m    :rtype: (:class:`LongTensor`, :class:`Tensor`)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     edge_index \u001b[39m=\u001b[39m radius_graph(pos, r\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcutoff, batch\u001b[39m=\u001b[39;49mbatch,\n\u001b[1;32m    260\u001b[0m                               max_num_neighbors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_num_neighbors)\n\u001b[1;32m    261\u001b[0m     row, col \u001b[39m=\u001b[39m edge_index\n\u001b[1;32m    262\u001b[0m     edge_weight \u001b[39m=\u001b[39m (pos[row] \u001b[39m-\u001b[39m pos[col])\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py:210\u001b[0m, in \u001b[0;36mradius_graph\u001b[0;34m(x, r, batch, loop, max_num_neighbors, flow, num_workers)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradius_graph\u001b[39m(x: Tensor, r: \u001b[39mfloat\u001b[39m, batch: OptTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m                  loop: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, max_num_neighbors: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m,\n\u001b[1;32m    177\u001b[0m                  flow: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    178\u001b[0m                  num_workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    179\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes graph edges to all points within a given distance.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m        edge_index = radius_graph(x, r=1.5, batch=batch, loop=False)\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_cluster\u001b[39m.\u001b[39;49mradius_graph(x, r, batch, loop, max_num_neighbors,\n\u001b[1;32m    211\u001b[0m                                       flow, num_workers)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 116, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 70, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n"
     ]
    }
   ],
   "source": [
    "output, jvp_out = jvp(\n",
    "    func=lambda x: f(x, data_batch_.atomic_numbers.long(), data_batch_.batch),\n",
    "    primals=(data_batch_.pos,),\n",
    "    tangents=(torch.ones_like(data_batch_.pos),),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2eea1ad8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jvp_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jvp_out\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jvp_out' is not defined"
     ]
    }
   ],
   "source": [
    "jvp_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d76d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = grad(lambda x: f(x, data_batch_.atomic_numbers.long(), data_batch_.batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e7125b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 116, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 70, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g(data_batch_\u001b[39m.\u001b[39;49mpos)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:1241\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m   1240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 1241\u001b[0m     results \u001b[39m=\u001b[39m grad_and_value(func, argnums, has_aux\u001b[39m=\u001b[39;49mhas_aux)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1242\u001b[0m     \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m   1243\u001b[0m         grad, (_, aux) \u001b[39m=\u001b[39m results\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/vmap.py:35\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/functorch/_src/eager_transforms.py:1111\u001b[0m, in \u001b[0;36mgrad_and_value.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m diff_args \u001b[39m=\u001b[39m _slice_argnums(args, argnums, as_tuple\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1109\u001b[0m tree_map_(partial(_create_differentiable, level\u001b[39m=\u001b[39mlevel), diff_args)\n\u001b[0;32m-> 1111\u001b[0m output \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m has_aux:\n\u001b[1;32m   1113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(output, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(output) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g \u001b[39m=\u001b[39m grad(\u001b[39mlambda\u001b[39;00m x: f(x, data_batch_\u001b[39m.\u001b[39;49matomic_numbers\u001b[39m.\u001b[39;49mlong(), data_batch_\u001b[39m.\u001b[39;49mbatch))\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mf\u001b[0;34m(pos, z, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(pos, z, batch):\n\u001b[0;32m---> 10\u001b[0m     h \u001b[39m=\u001b[39m schnet(\n\u001b[1;32m     11\u001b[0m         z\u001b[39m.\u001b[39;49mlong(), \n\u001b[1;32m     12\u001b[0m         pos,\n\u001b[1;32m     13\u001b[0m         batch\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 187\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, z, pos, batch)\u001b[0m\n\u001b[1;32m    184\u001b[0m batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(z) \u001b[39mif\u001b[39;00m batch \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m batch\n\u001b[1;32m    186\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(z)\n\u001b[0;32m--> 187\u001b[0m edge_index, edge_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minteraction_graph(pos, batch)\n\u001b[1;32m    188\u001b[0m edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_expansion(edge_weight)\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m i, interaction \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteractions):\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 259\u001b[0m, in \u001b[0;36mRadiusInteractionGraph.forward\u001b[0;34m(self, pos, batch)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, pos: Tensor, batch: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[1;32m    251\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39m        pos (Tensor): Coordinates of each atom.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39m    :rtype: (:class:`LongTensor`, :class:`Tensor`)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     edge_index \u001b[39m=\u001b[39m radius_graph(pos, r\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcutoff, batch\u001b[39m=\u001b[39;49mbatch,\n\u001b[1;32m    260\u001b[0m                               max_num_neighbors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_num_neighbors)\n\u001b[1;32m    261\u001b[0m     row, col \u001b[39m=\u001b[39m edge_index\n\u001b[1;32m    262\u001b[0m     edge_weight \u001b[39m=\u001b[39m (pos[row] \u001b[39m-\u001b[39m pos[col])\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_geometric/nn/pool/__init__.py:210\u001b[0m, in \u001b[0;36mradius_graph\u001b[0;34m(x, r, batch, loop, max_num_neighbors, flow, num_workers)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradius_graph\u001b[39m(x: Tensor, r: \u001b[39mfloat\u001b[39m, batch: OptTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m                  loop: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, max_num_neighbors: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m,\n\u001b[1;32m    177\u001b[0m                  flow: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msource_to_target\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    178\u001b[0m                  num_workers: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    179\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Computes graph edges to all points within a given distance.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m        edge_index = radius_graph(x, r=1.5, batch=batch, loop=False)\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m torch_cluster\u001b[39m.\u001b[39;49mradius_graph(x, r, batch, loop, max_num_neighbors,\n\u001b[1;32m    211\u001b[0m                                       flow, num_workers)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 116, in radius_graph\n\n    assert flow in ['source_to_target', 'target_to_source']\n    edge_index = radius(x, x, r, batch, batch,\n                 ~~~~~~ <--- HERE\n                        max_num_neighbors if loop else max_num_neighbors + 1,\n                        num_workers)\n  File \"/home/novelli/anaconda3/envs/ocp-models/lib/python3.9/site-packages/torch_cluster/radius.py\", line 70, in radius\n        ptr_y = torch.bucketize(arange, batch_y)\n\n    return torch.ops.torch_cluster.radius(x, y, ptr_x, ptr_y, r,\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n                                          max_num_neighbors, num_workers)\nRuntimeError: Cannot access data pointer of Tensor that doesn't have storage\n"
     ]
    }
   ],
   "source": [
    "g(data_batch_.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8efcc05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([940, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(data_batch_.pos, data_batch_.atomic_numbers.long(), data_batch_.batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9918b26f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "J = torch.autograd.functional.jacobian(\n",
    "    lambda x: f(x, data_batch_.atomic_numbers.long(), data_batch_.batch),\n",
    "    data_batch_.pos,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1ffe6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in schnet.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fa1564a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([940, 9, 940, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c38666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
